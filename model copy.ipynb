{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Exemple traité ===\n",
      "Tokenized Text:\n",
      "['Q', ':', 'Position', 'character', 'based', 'on', 'enemy', 'coordinates', 'in', 'lua', 'I', 'have', 'written', 'a', 'function', 'here', 'which', 'should', 'turn', 'my', 'character', 'based', 'on', 'enemy', 'coordinates', 'but', 'it', \"'\", 's', 'not', 'perfect', 'because', 'it', 'does', 'not', 'always', 'turn', 'where', 'I', 'want', 'it', 'to', 'and', 'perhaps', 'there', 'is', 'a', 'better', 'way', 'of', 'writing', 'it', 'local', 'myPosition', '=', '{', 'x', '=', '350', ',', 'y', '=', '355', '}', 'local', 'enemyPosition', '=', '{', 'x', '=', '352', ',', 'y', '=', '354', '}', 'local', 'xValue', ',', 'yValue', ',', 'xDir', ',', 'yDir', ',', 'dir', 'if', 'myPosition', '.', 'x', '>', 'enemyPosition', '.', 'x', 'then', 'xValue', '=', 'myPosition', '.', 'x', '-', 'enemyPosition', '.', 'x', 'elseif', 'myPosition', '.', 'x', '<', 'enemyPosition', '.', 'x', 'then', 'xValue', '=', 'myPosition', '.', 'x', '-', 'enemyPosition', '.', 'x', 'else', 'xValue', '=', '0', 'end', 'if', 'myPosition', '.', 'y', '>', 'enemyPosition', '.', 'y', 'then', 'yValue', '=', 'myPosition', '.', 'y', '-', 'enemyPosition', '.', 'y', 'elseif', 'myPosition', '.', 'y', '<', 'enemyPosition', '.', 'y', 'then', 'yValue', '=', 'myPosition', '.', 'y', '-', 'enemyPosition', '.', 'y', 'else', 'yValue', '=', '0', 'end', 'if', 'xValue', '<', '0', 'then', 'xDir', '=', '\"', 'TURN', 'RIGHT', '\"', 'elseif', 'xValue', '>', '0', 'then', 'xDir', '=', '\"', 'TURN', 'LEFT', '\"', 'end', 'if', 'yValue', '<', '0', 'then', 'yDir', '=', '\"', 'TURN', 'DOWN', '\"', 'elseif', 'yValue', '>', '0', 'then', 'yDir', '=', '\"', 'TURN', 'UP', '\"', 'end', 'if', 'xValue', '>', 'yValue', 'then', 'dir', '=', 'xDir', 'elseif', 'xValue', 'dir', '=', 'yDir', 'end', 'print', '(', '\"', 'Turn', ':', '\"', '.', '.', 'dir', ')', 'And', 'here', 'you', 'have', 'some', 'pictures', 'to', 'further', 'illustrate', 'what', 'I', 'have', 'in', 'mind', ':', 'As', 'you', 'can', 'see', 'on', 'the', 'pictures', ',', 'direction', 'depends', 'on', 'the', 'higher', 'number', '.']\n",
      "\n",
      "NER Spans:\n",
      " - Start: 14, End: 14, Entity Type: programming concept\n",
      " - Start: 9, End: 9, Entity Type: programming language\n",
      " - Start: 53, End: 53, Entity Type: variable\n",
      " - Start: 87, End: 87, Entity Type: variable\n",
      " - Start: 97, End: 97, Entity Type: variable\n",
      " - Start: 105, End: 105, Entity Type: variable\n",
      " - Start: 115, End: 115, Entity Type: variable\n",
      " - Start: 128, End: 128, Entity Type: variable\n",
      " - Start: 138, End: 138, Entity Type: variable\n",
      " - Start: 146, End: 146, Entity Type: variable\n",
      " - Start: 156, End: 156, Entity Type: variable\n",
      " - Start: 65, End: 65, Entity Type: variable\n",
      " - Start: 91, End: 91, Entity Type: variable\n",
      " - Start: 101, End: 101, Entity Type: variable\n",
      " - Start: 109, End: 109, Entity Type: variable\n",
      " - Start: 119, End: 119, Entity Type: variable\n",
      " - Start: 132, End: 132, Entity Type: variable\n",
      " - Start: 142, End: 142, Entity Type: variable\n",
      " - Start: 150, End: 150, Entity Type: variable\n",
      " - Start: 160, End: 160, Entity Type: variable\n",
      " - Start: 77, End: 77, Entity Type: variable\n",
      " - Start: 95, End: 95, Entity Type: variable\n",
      " - Start: 113, End: 113, Entity Type: variable\n",
      " - Start: 123, End: 123, Entity Type: variable\n",
      " - Start: 169, End: 169, Entity Type: variable\n",
      " - Start: 180, End: 180, Entity Type: variable\n",
      " - Start: 215, End: 215, Entity Type: variable\n",
      " - Start: 223, End: 223, Entity Type: variable\n",
      " - Start: 79, End: 79, Entity Type: variable\n",
      " - Start: 136, End: 136, Entity Type: variable\n",
      " - Start: 154, End: 154, Entity Type: variable\n",
      " - Start: 164, End: 164, Entity Type: variable\n",
      " - Start: 192, End: 192, Entity Type: variable\n",
      " - Start: 203, End: 203, Entity Type: variable\n",
      " - Start: 217, End: 217, Entity Type: variable\n",
      " - Start: 81, End: 81, Entity Type: variable\n",
      " - Start: 173, End: 173, Entity Type: variable\n",
      " - Start: 184, End: 184, Entity Type: variable\n",
      " - Start: 221, End: 221, Entity Type: variable\n",
      " - Start: 83, End: 83, Entity Type: variable\n",
      " - Start: 196, End: 196, Entity Type: variable\n",
      " - Start: 207, End: 207, Entity Type: variable\n",
      " - Start: 226, End: 226, Entity Type: variable\n",
      " - Start: 85, End: 85, Entity Type: variable\n",
      " - Start: 219, End: 219, Entity Type: variable\n",
      " - Start: 224, End: 224, Entity Type: variable\n",
      " - Start: 236, End: 236, Entity Type: variable\n",
      "\n",
      "Negative Entities:\n",
      "['database', 'Date']\n"
     ]
    }
   ],
   "source": [
    "# Charger les données traitées pour inspection\n",
    "with open('pilener_train.json', 'r') as f:\n",
    "    processed_data = json.load(f)\n",
    "\n",
    "# Afficher un exemple\n",
    "example_idx = 0  # Modifier cet indice pour voir d'autres exemples\n",
    "example = processed_data[example_idx]\n",
    "\n",
    "# Afficher avec une mise en forme claire\n",
    "print(\"=== Exemple traité ===\")\n",
    "print(\"Tokenized Text:\")\n",
    "print(example['tokenized_text'])\n",
    "print(\"\\nNER Spans:\")\n",
    "for span in example['ner']:\n",
    "    print(f\" - Start: {span[0]}, End: {span[1]}, Entity Type: {span[2]}\")\n",
    "print(\"\\nNegative Entities:\")\n",
    "print(example['negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "faut allez à lendroit ou est defini le model puis vous pouvez exec la suite dans lordre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\doria\\anaconda3\\envs\\vincentorch\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\Users\\doria\\anaconda3\\envs\\vincentorch\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GLiNER(\n",
       "  (encoder): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (entity_ffn): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (span_ffn): Sequential(\n",
       "    (0): Linear(in_features=1536, out_features=768, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (sigmoid): Sigmoid()\n",
       "  (loss_fn): BCELoss()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GLiNER(pretrained_model_name=\"microsoft/deberta-v3-base\", span_max_length=2, hidden_size=768)\n",
    "# Initialiser le modèle\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Data:   0%|          | 0/45889 [00:00<?, ?entry/s]Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Processing Data:  10%|▉         | 4389/45889 [00:15<02:24, 287.30entry/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error, not same size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Data:  34%|███▍      | 15533/45889 [00:54<01:44, 291.28entry/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error, not same size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Data:  38%|███▊      | 17449/45889 [01:00<01:36, 295.56entry/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error, not same size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Data:  53%|█████▎    | 24212/45889 [01:23<01:09, 309.70entry/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error, not same size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Data:  64%|██████▍   | 29374/45889 [01:40<00:52, 315.02entry/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error, not same size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Data:  73%|███████▎  | 33409/45889 [01:53<00:40, 309.37entry/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error, not same size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Data:  76%|███████▌  | 34919/45889 [01:58<00:34, 314.73entry/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error, not same size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Data:  88%|████████▊ | 40346/45889 [02:16<00:17, 314.23entry/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error, not same size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Data: 100%|██████████| 45889/45889 [02:34<00:00, 296.70entry/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "def prepare_data_for_training(processed_data, model, max_length=256, max_entity_per_seq = 25):\n",
    "    input_ids, labels, entity_tensors, attention_masks = [], [], [], []\n",
    "    entity_masks, sentence_masks = [], []\n",
    "\n",
    "    # Créer un mapping des types d'entités vers des entiers\n",
    "    entity_types = {entity for entry in processed_data for _, _, entity in entry[\"ner\"]}\n",
    "    special_tokens = [f\"[ENT] {entity}\" for entity in entity_types]\n",
    "    model.tokenizer.add_special_tokens({\"additional_special_tokens\": special_tokens})\n",
    "    model.encoder.resize_token_embeddings(len(model.tokenizer))\n",
    "\n",
    "    for entry in tqdm(processed_data, desc=\"Processing Data\", unit=\"entry\"):\n",
    "        tokenized_text = entry[\"tokenized_text\"]\n",
    "        ner_spans = entry[\"ner\"]\n",
    "                \n",
    "        # Générer le tensor de labels\n",
    "        label_tensor = torch.zeros(max_length, dtype=torch.long)\n",
    "        current_entity_id = []\n",
    "        current_entity_str = []\n",
    "\n",
    "        for start, end, entity_type in ner_spans:\n",
    "            if start < max_length and end < max_length and len(current_entity_str)<max_entity_per_seq:\n",
    "                entity_token_id = model.tokenizer.convert_tokens_to_ids(f'[ENT] {entity_type}')\n",
    "                label_tensor[start:end + 1] = entity_token_id\n",
    "\n",
    "                if entity_token_id not in current_entity_id:\n",
    "                    current_entity_id.append(entity_token_id)\n",
    "                if entity_type not in current_entity_str:\n",
    "                    current_entity_str.append(entity_type)\n",
    "\n",
    "        entity_tokens = \" \".join(f\"[ENT] {et}\" for et in current_entity_str)\n",
    "        \n",
    "        # Tokeniser la séquence principale\n",
    "        encoded = model.tokenizer(\n",
    "            tokenized_text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, \n",
    "            is_split_into_words=True, add_special_tokens=False\n",
    "        )\n",
    "\n",
    "        word_ids = encoded.word_ids()\n",
    "        first_subtoken_ids = [\n",
    "            encoded[\"input_ids\"][0, i].item() for i, word_id in enumerate(word_ids) \n",
    "            if word_id is not None and (i == 0 or word_ids[i - 1] != word_id)\n",
    "        ]\n",
    "\n",
    "        encoded_entity = model.tokenizer(\n",
    "            entity_tokens, return_tensors=\"pt\", padding=\"max_length\", truncation=True, \n",
    "            is_split_into_words=False, add_special_tokens=False\n",
    "        )\n",
    "\n",
    "        if len(current_entity_str) != len(encoded_entity[\"input_ids\"][0]) or len(tokenized_text) != len(first_subtoken_ids):\n",
    "            print(\"error, not same size\")\n",
    "            continue\n",
    "\n",
    "        encoded_entity = encoded_entity[\"input_ids\"][0].tolist() + [0]*(max_entity_per_seq-len(current_entity_str))\n",
    "\n",
    "        sep_id = model.tokenizer.convert_tokens_to_ids(f'[SEP]')\n",
    "\n",
    "        combined_ids = (\n",
    "            encoded_entity +\n",
    "            [sep_id] +\n",
    "            first_subtoken_ids\n",
    "        )\n",
    "\n",
    "        if len(combined_ids) != max_entity_per_seq + len(first_subtoken_ids) + 1:\n",
    "            print(\"error, not same size\")\n",
    "            continue\n",
    "\n",
    "        deleted_ids = max(len(combined_ids) - max_length,0)\n",
    "        combined_ids = combined_ids[:max_length]\n",
    "        combined_ids += [0] * (max_length - len(combined_ids))\n",
    "\n",
    "        # Créer l'attention mask\n",
    "        attention_mask = [1 if id != 0 else 0 for id in combined_ids]\n",
    "\n",
    "        # Masques spécifiques pour les entités et la phrase\n",
    "        entity_mask = [1 if i < len(current_entity_str) else 0 for i in range(len(combined_ids))]\n",
    "        sentence_mask = [1 if i > len(encoded_entity) and combined_ids[i] != 0 and combined_ids[i] != sep_id else 0 \n",
    "                         for i in range(len(combined_ids))]\n",
    "\n",
    "        # Vérification des tailles\n",
    "        if sum(entity_mask) != len(current_entity_str):\n",
    "            print(f\"Entity mask size mismatch: {sum(entity_mask)} != {len(current_entity_str)}\")\n",
    "            continue\n",
    "        if sum(sentence_mask) != len(tokenized_text)-deleted_ids:\n",
    "            print(f\"Sentence mask size mismatch: {sum(sentence_mask)} != {len(tokenized_text)-deleted_ids}\")\n",
    "            continue\n",
    "\n",
    "        current_entity_id = current_entity_id + [0]*(max_entity_per_seq-len(current_entity_str))\n",
    "\n",
    "        # Convertir les entités en un tensor\n",
    "        entity_tensor = torch.tensor(current_entity_id, dtype=torch.long)\n",
    "        \n",
    "        # Ajouter les données\n",
    "        input_ids.append(torch.tensor(combined_ids, dtype=torch.long))\n",
    "        labels.append(label_tensor)\n",
    "        entity_tensors.append(entity_tensor)\n",
    "        attention_masks.append(torch.tensor(attention_mask, dtype=torch.long))\n",
    "        entity_masks.append(torch.tensor(entity_mask, dtype=torch.long))\n",
    "        sentence_masks.append(torch.tensor(sentence_mask, dtype=torch.long))\n",
    "\n",
    "    return (\n",
    "        torch.stack(input_ids), \n",
    "        torch.stack(labels), \n",
    "        entity_tensors, \n",
    "        torch.stack(attention_masks), \n",
    "        torch.stack(entity_masks), \n",
    "        torch.stack(sentence_masks)\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# Charger les données générées précédemment\n",
    "with open('pilener_train.json', 'r') as f:\n",
    "    processed_data = json.load(f)\n",
    "\n",
    "# Préparer les données avec suivi d'avancement\n",
    "input_ids, labels, entity_tensors, attention_masks, entity_masks, sentence_masks = prepare_data_for_training(processed_data, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143177\n",
      "45881\n",
      "45881\n"
     ]
    }
   ],
   "source": [
    "print(len(model.tokenizer))\n",
    "print(len(input_ids))\n",
    "print(len(entity_tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme de input_ids : torch.Size([45881, 256])\n",
      "Forme de attention_masks : torch.Size([45881, 256])\n",
      "Forme de labels : torch.Size([45881, 256])\n",
      "Forme de entity_masks : torch.Size([45881, 256])\n",
      "Forme de sentence_masks : torch.Size([45881, 256])\n",
      "\n",
      "Exemple de input_ids (première entrée) :\n",
      "tensor([135536, 140280, 142239,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      2,   1729,\n",
      "           877,  18172,   1470,    636,    277,   4648,  14321,    267,  96792,\n",
      "           273,    286,   1223,    266,   1571,    422,    319,    403,    930,\n",
      "           312,   1470,    636,    277,   4648,  14321,    304,    278,    382,\n",
      "          1550,    298,    801,    401,    278,    490,    298,    489,    930,\n",
      "           399,    273,    409,    278,    264,    263,   1733,    343,    269,\n",
      "           266,    493,    384,    265,    898,    278,    588,    312,   1842,\n",
      "         13856,   1204,   1842,   7351,    366,   2982,   1842,  40059,  15805,\n",
      "           588,   4648,   1842,  13856,   1204,   1842,  42091,    366,   2982,\n",
      "          1842,  50238,  15805,    588,   1204,    366,   2982,    366,   1204,\n",
      "           366,   2982,    366,  30791,    337,    312,    323,   1204,   2108,\n",
      "          4648,    323,   1204,    393,   1204,   1842,    312,    323,   1204,\n",
      "           341,   4648,    323,   1204,    995,    312,    323,   1204,   2569,\n",
      "          4648,    323,   1204,    393,   1204,   1842,    312,    323,   1204,\n",
      "           341,   4648,    323,   1204,    995,   1204,   1842,    767,    513,\n",
      "           337,    312,    323,   2982,   2108,   4648,    323,   2982,    393,\n",
      "          2982,   1842,    312,    323,   2982,    341,   4648,    323,   2982,\n",
      "           995,    312,    323,   2982,   2569,   4648,    323,   2982,    393,\n",
      "          2982,   1842,    312,    323,   2982,    341,   4648,    323,   2982,\n",
      "           995,   2982,   1842,    767,    513,    337,   1204,   2569,    767,\n",
      "           393,   1204,   1842,    307,  47334,  21171,    307,    995,   1204,\n",
      "          2108,    767,    393,   1204,   1842,    307,  47334,  43424,    307,\n",
      "           513,    337,   2982,   2569,    767,    393,   2982,   1842,    307,\n",
      "         47334,  27920,    307,    995,   2982,   2108,    767,    393,   2982,\n",
      "          1842,    307,  47334,   9146,    307,    513,    337,   1204,   2108,\n",
      "          2982,    393,  30791,   1842,   1204,    995,   1204,  30791,   1842,\n",
      "          2982,    513,   2118,    287])\n",
      "\n",
      "Exemple de attention_masks (première entrée) :\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Exemple de labels (première entrée) :\n",
      "tensor([     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "        140280,      0,      0,      0,      0, 135536,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0, 142239,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0, 142239,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0, 142239,      0, 142239,      0,\n",
      "        142239,      0, 142239,      0, 142239,      0, 142239,      0,      0,\n",
      "             0, 142239,      0,      0,      0, 142239,      0, 142239,      0,\n",
      "             0,      0, 142239,      0,      0,      0, 142239,      0,      0,\n",
      "             0, 142239,      0,      0,      0, 142239,      0, 142239,      0,\n",
      "             0,      0, 142239,      0,      0,      0, 142239,      0,      0,\n",
      "             0,      0, 142239,      0,      0,      0, 142239,      0,      0,\n",
      "             0, 142239,      0, 142239,      0,      0,      0, 142239,      0,\n",
      "             0,      0, 142239,      0,      0,      0, 142239,      0,      0,\n",
      "             0, 142239,      0, 142239,      0,      0,      0, 142239,      0,\n",
      "             0,      0, 142239,      0,      0,      0,      0, 142239,      0,\n",
      "             0,      0, 142239,      0,      0,      0,      0,      0,      0,\n",
      "        142239,      0,      0,      0, 142239,      0,      0,      0,      0,\n",
      "             0,      0,      0, 142239,      0,      0,      0, 142239,      0,\n",
      "             0,      0,      0,      0,      0, 142239,      0,      0,      0,\n",
      "        142239,      0,      0,      0,      0,      0,      0,      0, 142239,\n",
      "             0, 142239,      0, 142239,      0, 142239,      0, 142239, 142239,\n",
      "             0, 142239,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0, 142239,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0])\n",
      "\n",
      "Exemple de entity_tensors (première entrée) :\n",
      "tensor([135536, 140280, 142239,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0])\n",
      "\n",
      "Exemple de entity_masks (première entrée) :\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n",
      "Exemple de sentence_masks (première entrée) :\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Afficher les formes des tensors principaux\n",
    "print(f\"Forme de input_ids : {input_ids.shape}\")\n",
    "print(f\"Forme de attention_masks : {attention_masks.shape}\")\n",
    "print(f\"Forme de labels : {labels.shape}\")\n",
    "print(f\"Forme de entity_masks : {entity_masks.shape}\")\n",
    "print(f\"Forme de sentence_masks : {sentence_masks.shape}\")\n",
    "\n",
    "# Afficher un exemple pour les tensors principaux\n",
    "print(\"\\nExemple de input_ids (première entrée) :\")\n",
    "print(input_ids[0])\n",
    "\n",
    "print(\"\\nExemple de attention_masks (première entrée) :\")\n",
    "print(attention_masks[0])\n",
    "\n",
    "print(\"\\nExemple de labels (première entrée) :\")\n",
    "print(labels[0])\n",
    "\n",
    "# Afficher un exemple pour les entity_tensors\n",
    "print(\"\\nExemple de entity_tensors (première entrée) :\")\n",
    "print(entity_tensors[0])\n",
    "\n",
    "# Afficher un exemple pour les entity_masks\n",
    "print(\"\\nExemple de entity_masks (première entrée) :\")\n",
    "print(entity_masks[0])\n",
    "\n",
    "# Afficher un exemple pour les sentence_masks\n",
    "print(\"\\nExemple de sentence_masks (première entrée) :\")\n",
    "print(sentence_masks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torch\n",
    "\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(self, input_ids, attention_masks, labels, entities,entity_masks,sentence_masks , max_span_length=2):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_masks = attention_masks\n",
    "        self.entity_masks = entity_masks\n",
    "        self.sentence_masks =sentence_masks\n",
    "        self.labels = labels  # Liste des labels pour chaque token\n",
    "        self.entities = entities  # Liste des entités uniques\n",
    "        self.max_span_length = max_span_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_id = self.input_ids[idx]\n",
    "        attention_mask = self.attention_masks[idx]\n",
    "        token_labels = self.labels[idx]  # Labels token-par-token\n",
    "        entity_ids = self.entities[idx]  # Entités pour cet exemple\n",
    "\n",
    "        num_tokens = len(input_id) - len(entity_ids) - 1\n",
    "        spans = [\n",
    "            (start, end)\n",
    "            for start in range(num_tokens)\n",
    "            for end in range(start, min(start + self.max_span_length, num_tokens))\n",
    "        ]\n",
    "        num_spans = len(spans)\n",
    "        num_entities = len(entity_ids)\n",
    "\n",
    "        # Matrice binaire : spans x entities\n",
    "        binary_labels = torch.zeros(num_spans, num_entities, dtype=torch.float)\n",
    "\n",
    "        for span_idx, (start, end) in enumerate(spans):\n",
    "            span_labels = token_labels[start:end + 1]\n",
    "            for entity_idx, entity_id in enumerate(entity_ids):\n",
    "                if all((label == entity_id and label != 0)  for label in span_labels):\n",
    "                    binary_labels[span_idx, entity_idx] = 1\n",
    "\n",
    "        return input_id, attention_mask, spans, entity_ids, binary_labels, sentence_masks, entity_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = int(len(input_ids) * proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input ID: tensor([135536, 140280, 142239,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      2,   1729,\n",
      "           877,  18172,   1470,    636,    277,   4648,  14321,    267,  96792,\n",
      "           273,    286,   1223,    266,   1571,    422,    319,    403,    930,\n",
      "           312,   1470,    636,    277,   4648,  14321,    304,    278,    382,\n",
      "          1550,    298,    801,    401,    278,    490,    298,    489,    930,\n",
      "           399,    273,    409,    278,    264,    263,   1733,    343,    269,\n",
      "           266,    493,    384,    265,    898,    278,    588,    312,   1842,\n",
      "         13856,   1204,   1842,   7351,    366,   2982,   1842,  40059,  15805,\n",
      "           588,   4648,   1842,  13856,   1204,   1842,  42091,    366,   2982,\n",
      "          1842,  50238,  15805,    588,   1204,    366,   2982,    366,   1204,\n",
      "           366,   2982,    366,  30791,    337,    312,    323,   1204,   2108,\n",
      "          4648,    323,   1204,    393,   1204,   1842,    312,    323,   1204,\n",
      "           341,   4648,    323,   1204,    995,    312,    323,   1204,   2569,\n",
      "          4648,    323,   1204,    393,   1204,   1842,    312,    323,   1204,\n",
      "           341,   4648,    323,   1204,    995,   1204,   1842,    767,    513,\n",
      "           337,    312,    323,   2982,   2108,   4648,    323,   2982,    393,\n",
      "          2982,   1842,    312,    323,   2982,    341,   4648,    323,   2982,\n",
      "           995,    312,    323,   2982,   2569,   4648,    323,   2982,    393,\n",
      "          2982,   1842,    312,    323,   2982,    341,   4648,    323,   2982,\n",
      "           995,   2982,   1842,    767,    513,    337,   1204,   2569,    767,\n",
      "           393,   1204,   1842,    307,  47334,  21171,    307,    995,   1204,\n",
      "          2108,    767,    393,   1204,   1842,    307,  47334,  43424,    307,\n",
      "           513,    337,   2982,   2569,    767,    393,   2982,   1842,    307,\n",
      "         47334,  27920,    307,    995,   2982,   2108,    767,    393,   2982,\n",
      "          1842,    307,  47334,   9146,    307,    513,    337,   1204,   2108,\n",
      "          2982,    393,  30791,   1842,   1204,    995,   1204,  30791,   1842,\n",
      "          2982,    513,   2118,    287])\n",
      "Spans: [(0, 0), (0, 1), (1, 1), (1, 2), (2, 2), (2, 3), (3, 3), (3, 4), (4, 4), (4, 5), (5, 5), (5, 6), (6, 6), (6, 7), (7, 7), (7, 8), (8, 8), (8, 9), (9, 9), (9, 10), (10, 10), (10, 11), (11, 11), (11, 12), (12, 12), (12, 13), (13, 13), (13, 14), (14, 14), (14, 15), (15, 15), (15, 16), (16, 16), (16, 17), (17, 17), (17, 18), (18, 18), (18, 19), (19, 19), (19, 20), (20, 20), (20, 21), (21, 21), (21, 22), (22, 22), (22, 23), (23, 23), (23, 24), (24, 24), (24, 25), (25, 25), (25, 26), (26, 26), (26, 27), (27, 27), (27, 28), (28, 28), (28, 29), (29, 29), (29, 30), (30, 30), (30, 31), (31, 31), (31, 32), (32, 32), (32, 33), (33, 33), (33, 34), (34, 34), (34, 35), (35, 35), (35, 36), (36, 36), (36, 37), (37, 37), (37, 38), (38, 38), (38, 39), (39, 39), (39, 40), (40, 40), (40, 41), (41, 41), (41, 42), (42, 42), (42, 43), (43, 43), (43, 44), (44, 44), (44, 45), (45, 45), (45, 46), (46, 46), (46, 47), (47, 47), (47, 48), (48, 48), (48, 49), (49, 49), (49, 50), (50, 50), (50, 51), (51, 51), (51, 52), (52, 52), (52, 53), (53, 53), (53, 54), (54, 54), (54, 55), (55, 55), (55, 56), (56, 56), (56, 57), (57, 57), (57, 58), (58, 58), (58, 59), (59, 59), (59, 60), (60, 60), (60, 61), (61, 61), (61, 62), (62, 62), (62, 63), (63, 63), (63, 64), (64, 64), (64, 65), (65, 65), (65, 66), (66, 66), (66, 67), (67, 67), (67, 68), (68, 68), (68, 69), (69, 69), (69, 70), (70, 70), (70, 71), (71, 71), (71, 72), (72, 72), (72, 73), (73, 73), (73, 74), (74, 74), (74, 75), (75, 75), (75, 76), (76, 76), (76, 77), (77, 77), (77, 78), (78, 78), (78, 79), (79, 79), (79, 80), (80, 80), (80, 81), (81, 81), (81, 82), (82, 82), (82, 83), (83, 83), (83, 84), (84, 84), (84, 85), (85, 85), (85, 86), (86, 86), (86, 87), (87, 87), (87, 88), (88, 88), (88, 89), (89, 89), (89, 90), (90, 90), (90, 91), (91, 91), (91, 92), (92, 92), (92, 93), (93, 93), (93, 94), (94, 94), (94, 95), (95, 95), (95, 96), (96, 96), (96, 97), (97, 97), (97, 98), (98, 98), (98, 99), (99, 99), (99, 100), (100, 100), (100, 101), (101, 101), (101, 102), (102, 102), (102, 103), (103, 103), (103, 104), (104, 104), (104, 105), (105, 105), (105, 106), (106, 106), (106, 107), (107, 107), (107, 108), (108, 108), (108, 109), (109, 109), (109, 110), (110, 110), (110, 111), (111, 111), (111, 112), (112, 112), (112, 113), (113, 113), (113, 114), (114, 114), (114, 115), (115, 115), (115, 116), (116, 116), (116, 117), (117, 117), (117, 118), (118, 118), (118, 119), (119, 119), (119, 120), (120, 120), (120, 121), (121, 121), (121, 122), (122, 122), (122, 123), (123, 123), (123, 124), (124, 124), (124, 125), (125, 125), (125, 126), (126, 126), (126, 127), (127, 127), (127, 128), (128, 128), (128, 129), (129, 129), (129, 130), (130, 130), (130, 131), (131, 131), (131, 132), (132, 132), (132, 133), (133, 133), (133, 134), (134, 134), (134, 135), (135, 135), (135, 136), (136, 136), (136, 137), (137, 137), (137, 138), (138, 138), (138, 139), (139, 139), (139, 140), (140, 140), (140, 141), (141, 141), (141, 142), (142, 142), (142, 143), (143, 143), (143, 144), (144, 144), (144, 145), (145, 145), (145, 146), (146, 146), (146, 147), (147, 147), (147, 148), (148, 148), (148, 149), (149, 149), (149, 150), (150, 150), (150, 151), (151, 151), (151, 152), (152, 152), (152, 153), (153, 153), (153, 154), (154, 154), (154, 155), (155, 155), (155, 156), (156, 156), (156, 157), (157, 157), (157, 158), (158, 158), (158, 159), (159, 159), (159, 160), (160, 160), (160, 161), (161, 161), (161, 162), (162, 162), (162, 163), (163, 163), (163, 164), (164, 164), (164, 165), (165, 165), (165, 166), (166, 166), (166, 167), (167, 167), (167, 168), (168, 168), (168, 169), (169, 169), (169, 170), (170, 170), (170, 171), (171, 171), (171, 172), (172, 172), (172, 173), (173, 173), (173, 174), (174, 174), (174, 175), (175, 175), (175, 176), (176, 176), (176, 177), (177, 177), (177, 178), (178, 178), (178, 179), (179, 179), (179, 180), (180, 180), (180, 181), (181, 181), (181, 182), (182, 182), (182, 183), (183, 183), (183, 184), (184, 184), (184, 185), (185, 185), (185, 186), (186, 186), (186, 187), (187, 187), (187, 188), (188, 188), (188, 189), (189, 189), (189, 190), (190, 190), (190, 191), (191, 191), (191, 192), (192, 192), (192, 193), (193, 193), (193, 194), (194, 194), (194, 195), (195, 195), (195, 196), (196, 196), (196, 197), (197, 197), (197, 198), (198, 198), (198, 199), (199, 199), (199, 200), (200, 200), (200, 201), (201, 201), (201, 202), (202, 202), (202, 203), (203, 203), (203, 204), (204, 204), (204, 205), (205, 205), (205, 206), (206, 206), (206, 207), (207, 207), (207, 208), (208, 208), (208, 209), (209, 209), (209, 210), (210, 210), (210, 211), (211, 211), (211, 212), (212, 212), (212, 213), (213, 213), (213, 214), (214, 214), (214, 215), (215, 215), (215, 216), (216, 216), (216, 217), (217, 217), (217, 218), (218, 218), (218, 219), (219, 219), (219, 220), (220, 220), (220, 221), (221, 221), (221, 222), (222, 222), (222, 223), (223, 223), (223, 224), (224, 224), (224, 225), (225, 225), (225, 226), (226, 226), (226, 227), (227, 227), (227, 228), (228, 228), (228, 229), (229, 229)]\n",
      "Entity IDs: tensor([135536, 140280, 142239,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0])\n",
      "Binary Labels: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Créer le dataset\n",
    "dataset = NERDataset(input_ids[:ind], attention_masks[:ind], labels[:ind], entity_tensors[:ind],entity_masks[:ind],sentence_masks[:ind])\n",
    "\n",
    "# Exemple de récupération d'une entrée\n",
    "input_id, attention_mask, spans, entity_ids, binary_labels, sentence_masks, entity_masks = dataset[0]\n",
    "\n",
    "print(\"Input ID:\", input_id)\n",
    "print(\"Spans:\", spans)\n",
    "print(\"Entity IDs:\", entity_ids)\n",
    "print(\"Binary Labels:\", binary_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids, attention_masks, spans, entity_ids, binary_labels, sentence_masks, entity_masks = zip(*batch)\n",
    "\n",
    "    # Trouver les tailles maximales pour le padding\n",
    "    max_len = max(len(ids) for ids in input_ids)  # Longueur max des tokens\n",
    "    max_spans = max(len(s) for s in spans)  # Nombre max de spans\n",
    "    max_entities = max(len(e) for e in entity_ids)  # Nombre max d'entités\n",
    "\n",
    "    # Padding des input_ids et attention_masks\n",
    "    # padded_input_ids = torch.stack([\n",
    "    #     torch.cat([ids, torch.zeros(max_len - len(ids), dtype=torch.long)])\n",
    "    #     for ids in input_ids\n",
    "    # ])\n",
    "    # padded_attention_masks = torch.stack([\n",
    "    #     torch.cat([mask, torch.zeros(max_len - len(mask), dtype=torch.long)])\n",
    "    #     for mask in attention_masks\n",
    "    # ])\n",
    "\n",
    "    # Padding des spans\n",
    "    # spans = torch.stack([\n",
    "    #     torch.cat([torch.tensor(s, dtype=torch.long), torch.zeros((max_spans - len(s), 2), dtype=torch.long)])\n",
    "    #     for s in spans\n",
    "    # ])\n",
    "\n",
    "    # Padding des entity_ids\n",
    "    # padded_entity_ids = torch.stack([\n",
    "    #     torch.cat([e, torch.zeros(max_entities - len(e), dtype=torch.long)])\n",
    "    #     for e in entity_ids\n",
    "    # ])\n",
    "\n",
    "    # Padding des binary_labels\n",
    "    # binary_labels = torch.stack([\n",
    "    #     torch.cat([\n",
    "    #         torch.cat([bl, torch.zeros(max_spans - bl.size(0), bl.size(1))], dim=0) if bl.size(0) < max_spans else bl,\n",
    "    #         torch.zeros(max_spans, max_entities - bl.size(1)) if bl.size(1) < max_entities else torch.zeros(0)\n",
    "    #     ], dim=1)\n",
    "    #     for bl in binary_labels\n",
    "    # ])\n",
    "\n",
    "        # Conversion en tensors\n",
    "        #spans = [torch.tensor(s, dtype=torch.long) for s in spans]\n",
    "    input_ids = torch.stack([ids.clone().detach() for ids in input_ids])\n",
    "    attention_masks = torch.stack([mask.clone().detach() for mask in attention_masks]) \n",
    "    entity_ids = torch.stack([e.clone().detach() for e in entity_ids])\n",
    "    binary_labels = torch.stack([bl.clone().detach() for bl in binary_labels])\n",
    "    sentence_masks = torch.stack([sm.clone().detach() for sm in sentence_masks])\n",
    "    entity_masks = torch.stack([em.clone().detach() for em in entity_masks])\n",
    "    spans = torch.tensor([span for span in spans], dtype=torch.long)\n",
    "\n",
    "    return input_ids, attention_masks, spans, entity_ids, binary_labels, sentence_masks, entity_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 230\n",
      "Validation size: 29\n",
      "Test size: 29\n"
     ]
    }
   ],
   "source": [
    "# Définir les proportions pour le train, validation et test\n",
    "train_ratio = 0.8  # 80% des données pour l'entraînement\n",
    "val_ratio = 0.1    # 10% des données pour la validation\n",
    "test_ratio = 0.1   # 10% des données pour le test\n",
    "\n",
    "# Calculer les tailles des différents ensembles\n",
    "train_size = int(train_ratio * len(dataset))\n",
    "val_size = int(val_ratio * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "# Diviser les données en train, validation, et test\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Créer les DataLoaders pour chaque ensemble\n",
    "batch_size = 16  # Ajuster selon vos besoins\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "# Vérification des tailles\n",
    "print(f\"Train size: {len(train_loader)}\")\n",
    "print(f\"Validation size: {len(val_loader)}\")\n",
    "print(f\"Test size: {len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## architecture model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "class GLiNER(nn.Module):\n",
    "    def __init__(self, pretrained_model_name=\"microsoft/deberta-v3-base\", span_max_length=2, hidden_size=768):\n",
    "        super(GLiNER, self).__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "        self.encoder = AutoModel.from_pretrained(pretrained_model_name)\n",
    "\n",
    "        self.entity_ffn = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size)\n",
    "        )\n",
    "        \n",
    "        self.span_ffn = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size)\n",
    "        )\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.span_max_length = span_max_length\n",
    "        self.loss_fn = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "\n",
    "    def forward(self, input_ids, attention_masks, entity_types, spans, sentence_masks, entity_masks, binary_labels=None):\n",
    "        # print(\"Input IDs shape:\", input_ids.shape)\n",
    "        # print(\"Attention mask shape:\", attention_masks.shape)\n",
    "        # Passer input_ids et attention_masks au modèle\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_masks)\n",
    "        token_embeddings = outputs.last_hidden_state\n",
    "    \n",
    "        entity_embeddings, text_embeddings = self.split_embeddings(token_embeddings,len(entity_types[0]))\n",
    "        \n",
    "\n",
    "        refined_entity_embeddings = self.entity_ffn(entity_embeddings)\n",
    "        \n",
    "        span_scores = self.compute_span_scores(refined_entity_embeddings, text_embeddings, spans)\n",
    "\n",
    "        if binary_labels is not None:\n",
    "            loss = self.compute_loss(span_scores, binary_labels)\n",
    "            return span_scores, loss\n",
    "        \n",
    "        return span_scores\n",
    "\n",
    "\n",
    "    def split_embeddings(self, token_embeddings, num_entity_types = 25):\n",
    "        entity_embeddings = token_embeddings[:, 0:num_entity_types, :]\n",
    "        text_embeddings = token_embeddings[:, num_entity_types + 1:, :]\n",
    "        \n",
    "        return entity_embeddings, text_embeddings\n",
    "\n",
    "    \n",
    "    def compute_span_scores(self, entity_embeddings, text_embeddings, spans):\n",
    "        \"\"\"\n",
    "        Calcule les scores des spans en une seule passe vectorisée, \n",
    "        en supposant que tous les spans sont valides.\n",
    "        \"\"\"\n",
    "        batch_size, text_length, hidden_size = text_embeddings.shape\n",
    "\n",
    "        # Conversion des spans en tensor directement\n",
    "        spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
    "\n",
    "        # Récupération des embeddings des spans\n",
    "        i_indices = spans_tensor[:, :, 0].unsqueeze(-1).expand(-1, -1, hidden_size)  # (batch, num_spans, hidden_size)\n",
    "        j_indices = spans_tensor[:, :, 1].unsqueeze(-1).expand(-1, -1, hidden_size)\n",
    "\n",
    "        start_embeddings = torch.gather(text_embeddings, 1, i_indices)  # (batch, num_spans, hidden_size)\n",
    "        end_embeddings = torch.gather(text_embeddings, 1, j_indices)    # (batch, num_spans, hidden_size)\n",
    "\n",
    "        # Concaténer les embeddings des extrémités et passer dans la FFN\n",
    "        span_reprs = torch.cat([start_embeddings, end_embeddings], dim=-1)  # (batch, num_spans, 2 * hidden_size)\n",
    "        span_reprs = self.span_ffn(span_reprs)                              # (batch, num_spans, hidden_size)\n",
    "\n",
    "        # Calcul des scores pour toutes les entités\n",
    "        scores = torch.einsum(\"bsh,beh->bse\", span_reprs, entity_embeddings)  # (batch, num_spans, num_entity_types)\n",
    "\n",
    "        # Appliquer la sigmoïde pour les scores finaux\n",
    "        span_scores = self.sigmoid(scores)\n",
    "\n",
    "        return span_scores\n",
    "\n",
    "\n",
    "    def compute_loss(self, span_scores, binary_labels):\n",
    "        \"\"\"\n",
    "        Calcul de la perte binaire cross-entropy entre les scores et les étiquettes.\n",
    "        \"\"\"\n",
    "        # print(f\"span_scores shape: {span_scores.shape}\")\n",
    "        # print(f\"binary_labels shape: {binary_labels.shape}\")\n",
    "\n",
    "        # Appliquer la perte\n",
    "        loss = self.loss_fn(span_scores, binary_labels)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/230 [00:00<?, ?batch/s]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Training: 100%|██████████| 230/230 [21:25<00:00,  5.59s/batch, Batch Loss=0.0154] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0276\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 230/230 [21:36<00:00,  5.64s/batch, Batch Loss=0.0149] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0162\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 230/230 [21:40<00:00,  5.66s/batch, Batch Loss=0.0142] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0154\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 230/230 [22:48<00:00,  5.95s/batch, Batch Loss=0.0139] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0150\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 230/230 [24:26<00:00,  6.38s/batch, Batch Loss=0.0138] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Hyperparamètres\n",
    "num_epochs = 5\n",
    "learning_rate = 1e-5\n",
    "\n",
    "# Optimiseur et scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = get_scheduler(\n",
    "    \"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * num_epochs\n",
    ")\n",
    "\n",
    "# Fonction d'entraînement avec tqdm\n",
    "def train_epoch(model, train_loader, optimizer, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    # Ajout de tqdm pour afficher la progression\n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\", unit=\"batch\")\n",
    "    for batch in progress_bar:\n",
    "        input_ids, attention_masks, spans, entity_ids, binary_labels, sentence_masks, entity_masks = [b.to(device) for b in batch]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        span_scores, loss = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_masks=attention_masks,\n",
    "            entity_types=entity_ids,\n",
    "            spans=spans,\n",
    "            binary_labels=binary_labels,\n",
    "            sentence_masks=sentence_masks,\n",
    "            entity_masks=entity_masks\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Mise à jour de la barre de progression\n",
    "        progress_bar.set_postfix({\"Batch Loss\": loss.item()})\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    return avg_loss\n",
    "\n",
    "# Boucle d'entraînement avec tqdm\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler)\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Fonction pour calculer la précision, le rappel, le F1-score et la matrice de confusion\n",
    "def calculate_metrics(binary_scores, binary_labels):\n",
    "    # Déplacer les tensors vers le CPU avant de les convertir en NumPy\n",
    "    binary_scores_flat = binary_scores.cpu().flatten()\n",
    "    binary_labels_flat = binary_labels.cpu().flatten()\n",
    "\n",
    "    # Calcul des métriques\n",
    "    precision = precision_score(binary_labels_flat, binary_scores_flat)\n",
    "    recall = recall_score(binary_labels_flat, binary_scores_flat)\n",
    "    f1 = f1_score(binary_labels_flat, binary_scores_flat)\n",
    "\n",
    "    # Matrice de confusion\n",
    "    cm = confusion_matrix(binary_labels_flat, binary_scores_flat)\n",
    "\n",
    "    return precision, recall, f1, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(confusion_matrix, normalize=False):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    # Normalisation de la matrice de confusion si nécessaire\n",
    "    if normalize:\n",
    "        confusion_matrix = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    print(confusion_matrix)\n",
    "    # Affichage de la matrice de confusion avec format ajusté\n",
    "    sns.heatmap(confusion_matrix, annot=True, fmt='.4f' if normalize else 'g', cmap='Blues', cbar=False, \n",
    "                xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "                yticklabels=['True Negative', 'True Positive'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(model, test_loader):\n",
    "    model.eval()  # Passer en mode évaluation\n",
    "    total_loss = 0\n",
    "    test_loss = 0\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_f1 = 0\n",
    "    confusion_matrix_total = torch.zeros(2, 2)  # Confusion matrix for binary classification\n",
    "\n",
    "    progress_bar = tqdm(test_loader, desc=\"Testing\", unit=\"batch\")\n",
    "    with torch.no_grad():  # Désactiver les gradients pour la phase de test\n",
    "        for batch in progress_bar:\n",
    "            input_ids, attention_masks, spans, entity_ids, binary_labels, sentence_masks, entity_masks = [b.to(device) for b in batch]\n",
    "\n",
    "            span_scores, loss = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_masks=attention_masks,\n",
    "                entity_types=entity_ids,\n",
    "                spans=spans,\n",
    "                binary_labels=binary_labels,\n",
    "                sentence_masks=sentence_masks,\n",
    "                entity_masks=entity_masks\n",
    "            )\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Calcul des autres métriques\n",
    "            binary_scores = (span_scores >= 0.5).float()  # Convertir les scores en prédictions binaires\n",
    "            precision, recall, f1, cm = calculate_metrics(binary_scores, binary_labels)\n",
    "            \n",
    "            total_precision += precision\n",
    "            total_recall += recall\n",
    "            total_f1 += f1\n",
    "            confusion_matrix_total += torch.tensor(cm)\n",
    "\n",
    "            # Mise à jour de la barre de progression\n",
    "            progress_bar.set_postfix({\"Batch Loss\": loss.item()})\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    # Moyenne des métriques\n",
    "    average_precision = total_precision / len(test_loader)\n",
    "    average_recall = total_recall / len(test_loader)\n",
    "    average_f1 = total_f1 / len(test_loader)\n",
    "    confusion_matrix_total = confusion_matrix_total.numpy()\n",
    "\n",
    "    return avg_loss, average_precision,average_recall,average_f1,confusion_matrix_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/29 [00:00<?, ?batch/s]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:   3%|▎         | 1/29 [00:04<02:03,  4.42s/batch, Batch Loss=0.0142]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:   7%|▋         | 2/29 [00:09<02:02,  4.53s/batch, Batch Loss=0.0116]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:  10%|█         | 3/29 [00:13<01:57,  4.52s/batch, Batch Loss=0.0168]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:  14%|█▍        | 4/29 [00:18<01:54,  4.59s/batch, Batch Loss=0.0134]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:  17%|█▋        | 5/29 [00:22<01:51,  4.63s/batch, Batch Loss=0.0128]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:  21%|██        | 6/29 [00:27<01:46,  4.62s/batch, Batch Loss=0.0136]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:  24%|██▍       | 7/29 [00:32<01:41,  4.61s/batch, Batch Loss=0.0175]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:  28%|██▊       | 8/29 [00:36<01:36,  4.59s/batch, Batch Loss=0.0192]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:  31%|███       | 9/29 [00:41<01:33,  4.66s/batch, Batch Loss=0.0138]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:  34%|███▍      | 10/29 [00:46<01:28,  4.65s/batch, Batch Loss=0.0168]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:  38%|███▊      | 11/29 [00:50<01:23,  4.62s/batch, Batch Loss=0.015] C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:  41%|████▏     | 12/29 [00:55<01:18,  4.60s/batch, Batch Loss=0.0157]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:  45%|████▍     | 13/29 [00:59<01:13,  4.58s/batch, Batch Loss=0.0144]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:  48%|████▊     | 14/29 [01:04<01:08,  4.58s/batch, Batch Loss=0.0109]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:  52%|█████▏    | 15/29 [01:08<01:04,  4.58s/batch, Batch Loss=0.0107]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:  55%|█████▌    | 16/29 [01:13<00:59,  4.59s/batch, Batch Loss=0.00949]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:  59%|█████▊    | 17/29 [01:18<00:54,  4.56s/batch, Batch Loss=0.0162] C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:  62%|██████▏   | 18/29 [01:22<00:50,  4.55s/batch, Batch Loss=0.0156]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "c:\\Users\\doria\\anaconda3\\envs\\vincentorch\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Testing:  66%|██████▌   | 19/29 [01:27<00:46,  4.61s/batch, Batch Loss=0.0131]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:  69%|██████▉   | 20/29 [01:32<00:41,  4.64s/batch, Batch Loss=0.0143]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:  72%|███████▏  | 21/29 [01:36<00:36,  4.62s/batch, Batch Loss=0.0133]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:  76%|███████▌  | 22/29 [01:41<00:32,  4.64s/batch, Batch Loss=0.0117]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:  79%|███████▉  | 23/29 [01:45<00:27,  4.64s/batch, Batch Loss=0.0162]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:  83%|████████▎ | 24/29 [01:50<00:23,  4.69s/batch, Batch Loss=0.0132]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:  86%|████████▌ | 25/29 [01:55<00:18,  4.71s/batch, Batch Loss=0.00896]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:  90%|████████▉ | 26/29 [02:00<00:14,  4.71s/batch, Batch Loss=0.0122] C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:  93%|█████████▎| 27/29 [02:04<00:09,  4.71s/batch, Batch Loss=0.014] C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing:  97%|█████████▋| 28/29 [02:09<00:04,  4.65s/batch, Batch Loss=0.0152]C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_4712\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n",
      "Testing: 100%|██████████| 29/29 [02:12<00:00,  4.58s/batch, Batch Loss=0.0206]\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_precision, test_recall, test_f1, cm = test_epoch(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0142\n",
      "Test Precision: 0.4262\n",
      "Test Recall: 0.0236\n",
      "Test F1 Score: 0.0417\n",
      "[[9.99906029e-01 9.39705168e-05]\n",
      " [9.77846926e-01 2.21530745e-02]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "plot_confusion_matrix(cm,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cm[0, 0] = TN\n",
    "- cm[0, 1] = FP\n",
    "- cm[1, 0] = FN\n",
    "- cm[1, 1] = TP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save & Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#load \n",
    "model = torch.load(\"model_fullBest2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le modèle complet\n",
    "torch.save(model, \"model_fullBest2.pth\")\n",
    "# Sauvegarder le modèle\n",
    "torch.save(model.state_dict(), \"modelBest2.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phrase d'exemple\n",
    "sentence = \"Alain Farley works at McGill University\"\n",
    "entity_types_to_detect = [\"person\", \"organization\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence = \"Marie Dupont is a data scientist at OpenAI and she specializes in Python programming.\"\n",
    "# entity_types_to_detect = [\"person\", \"organization\",\"programming language\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_entity_per_seq = 25\n",
    "max_length = 256\n",
    "max_span_length = 2\n",
    "threshold_score = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_entity_id = []\n",
    "current_entity_str = []\n",
    "\n",
    "for entity_type in entity_types_to_detect:\n",
    "    entity_token_id = model.tokenizer.convert_tokens_to_ids(f'[ENT] {entity_type}')\n",
    "    if entity_token_id not in current_entity_id:\n",
    "        current_entity_id.append(entity_token_id)\n",
    "    if entity_type not in current_entity_str:\n",
    "        current_entity_str.append(entity_type)\n",
    "\n",
    "entity_tokens = \" \".join(f\"[ENT] {et}\" for et in current_entity_str)\n",
    "\n",
    "# Tokeniser la séquence principale\n",
    "encoded = model.tokenizer(\n",
    "    sentence.split(), return_tensors=\"pt\", padding=\"max_length\", truncation=True, \n",
    "    is_split_into_words=True, add_special_tokens=False\n",
    ")\n",
    "\n",
    "word_ids = encoded.word_ids()\n",
    "first_subtoken_ids = [\n",
    "    encoded[\"input_ids\"][0, i].item() for i, word_id in enumerate(word_ids) \n",
    "    if word_id is not None and (i == 0 or word_ids[i - 1] != word_id)\n",
    "]\n",
    "\n",
    "encoded_entity = model.tokenizer(\n",
    "    entity_tokens, return_tensors=\"pt\", padding=\"max_length\", truncation=True, \n",
    "    is_split_into_words=False, add_special_tokens=False\n",
    ")\n",
    "\n",
    "encoded_entity = encoded_entity[\"input_ids\"][0].tolist() + [0]*(max_entity_per_seq-len(current_entity_str))\n",
    "\n",
    "sep_id = model.tokenizer.convert_tokens_to_ids(f'[SEP]')\n",
    "\n",
    "combined_ids = (\n",
    "    encoded_entity +\n",
    "    [sep_id] +\n",
    "    first_subtoken_ids\n",
    ")\n",
    "\n",
    "deleted_ids = max(len(combined_ids) - max_length,0)\n",
    "combined_ids = combined_ids[:max_length]\n",
    "combined_ids += [0] * (max_length - len(combined_ids))\n",
    "\n",
    "# Créer l'attention mask\n",
    "attention_mask = [1 if id != 0 else 0 for id in combined_ids]\n",
    "\n",
    "# Masques spécifiques pour les entités et la phrase\n",
    "entity_mask = [1 if i < len(current_entity_str) else 0 for i in range(len(combined_ids))]\n",
    "sentence_mask = [1 if i > len(encoded_entity) and combined_ids[i] != 0 and combined_ids[i] != sep_id else 0 \n",
    "                    for i in range(len(combined_ids))]\n",
    "\n",
    "current_entity_id = current_entity_id + [0]*(max_entity_per_seq-len(current_entity_str))\n",
    "\n",
    "# Convertir les entités en un tensor\n",
    "entity_tensor = torch.tensor(current_entity_id, dtype=torch.long)\n",
    "\n",
    "# Ajouter les données\n",
    "input_ids_tensor = torch.tensor(combined_ids, dtype=torch.long)\n",
    "attention_mask_tensor = torch.tensor(attention_mask, dtype=torch.long)\n",
    "entity_mask_tensor =torch.tensor(entity_mask, dtype=torch.long)\n",
    "sentence_mask_tensor = torch.tensor(sentence_mask, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = len(input_ids_tensor) - len(entity_tensor) - 1\n",
    "spans = [\n",
    "    (start, end)\n",
    "    for start in range(num_tokens)\n",
    "    for end in range(start, min(start + max_span_length, num_tokens))\n",
    "]\n",
    "\n",
    "spans_tensor = torch.tensor(spans, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doria\\AppData\\Local\\Temp\\ipykernel_19204\\3357513992.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spans_tensor = torch.stack([torch.tensor(s, device=text_embeddings.device) for s in spans])  # (batch, num_spans, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span scores: tensor([[[4.3896e-01, 4.2323e-01, 3.1613e-06,  ..., 3.1613e-06,\n",
      "          3.1613e-06, 3.1613e-06],\n",
      "         [4.2792e-01, 4.1066e-01, 3.8305e-06,  ..., 3.8305e-06,\n",
      "          3.8305e-06, 3.8305e-06],\n",
      "         [4.1359e-01, 3.5814e-01, 3.2164e-06,  ..., 3.2164e-06,\n",
      "          3.2164e-06, 3.2164e-06],\n",
      "         ...,\n",
      "         [3.2433e-05, 1.0733e-05, 3.0504e-08,  ..., 3.0504e-08,\n",
      "          3.0504e-08, 3.0504e-08],\n",
      "         [3.2433e-05, 1.0733e-05, 3.0504e-08,  ..., 3.0504e-08,\n",
      "          3.0504e-08, 3.0504e-08],\n",
      "         [3.2433e-05, 1.0733e-05, 3.0504e-08,  ..., 3.0504e-08,\n",
      "          3.0504e-08, 3.0504e-08]]], device='cuda:0')\n",
      "Binary Span Scores: tensor([[[1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]], device='cuda:0', dtype=torch.int32)\n",
      "Nombre de 1: 10\n",
      "Masked Binary Span Scores: tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]], device='cuda:0', dtype=torch.int32)\n",
      "Masked Binary Span Scores: tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]], device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Passage en mode évaluation\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model.to(device)\n",
    "# Préparation des données de test\n",
    "# Assurez-vous que `input_ids_tensor`, `attention_mask_tensor`, `entity_tensor`, \n",
    "# `entity_mask_tensor`, `sentence_mask_tensor`, et `spans` soient bien définis.\n",
    "\n",
    "with torch.no_grad():  # Pas besoin de calculer les gradients en mode test\n",
    "    span_scores = model(\n",
    "        input_ids=input_ids_tensor.unsqueeze(0).to(device),  # Ajout d'une dimension batch\n",
    "        attention_masks=attention_mask_tensor.unsqueeze(0).to(device),\n",
    "        entity_types=entity_tensor.unsqueeze(0).to(device),\n",
    "        spans=spans_tensor.unsqueeze(0).to(device),\n",
    "        sentence_masks=sentence_mask_tensor.unsqueeze(0).to(device),\n",
    "        entity_masks=entity_mask_tensor.unsqueeze(0).to(device)\n",
    "    )\n",
    "\n",
    "# span_scores contient les scores prédites pour chaque span et chaque entité\n",
    "print(\"Span scores:\", span_scores)\n",
    "\n",
    "# Conversion des span scores en valeurs binaires\n",
    "binary_span_scores = (span_scores > threshold_score).int()\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Binary Span Scores:\", binary_span_scores)\n",
    "\n",
    "# Comptage des valeurs 1 dans tout le tenseur\n",
    "num_ones = binary_span_scores.sum().item()\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Nombre de 1:\", num_ones)\n",
    "\n",
    "# Création d'un masque avec des 0 et 1 représentant la valeur la plus élevée dans chaque liste\n",
    "# Initialisation d'un masque de mêmes dimensions que span_scores\n",
    "max_mask = torch.zeros_like(span_scores, dtype=torch.int)\n",
    "\n",
    "# Parcourir chaque batch, span et entité pour identifier les indices des max\n",
    "for i in range(span_scores.size(1)):  # Dimension des spans\n",
    "    for j in range(span_scores.size(2)):  # Dimension des entités\n",
    "        # Trouver l'indice de la valeur maximale dans la liste\n",
    "        max_index = torch.argmax(span_scores[0, i, :])  # Corrigé pour les dimensions\n",
    "        # Définir 1 à cet indice dans le masque\n",
    "        max_mask[0, i, max_index] = 1  # Corrigé pour les dimensions\n",
    "\n",
    "# Appliquer le masque sur binary_span_scores\n",
    "masked_binary_span_scores = binary_span_scores * max_mask\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Masked Binary Span Scores:\", masked_binary_span_scores)\n",
    "\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Masked Binary Span Scores:\", masked_binary_span_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Span Scores with Spans:\n",
      "Example 1:\n",
      "Span (0, 0): [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (0, 1): [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (1, 1): [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (1, 2): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (2, 2): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (2, 3): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (3, 3): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (3, 4): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (4, 4): [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (4, 5): [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (5, 5): [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (5, 6): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (6, 6): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (6, 7): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (7, 7): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (7, 8): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (8, 8): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (8, 9): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (9, 9): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (9, 10): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (10, 10): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (10, 11): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (11, 11): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (11, 12): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (12, 12): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (12, 13): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (13, 13): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (13, 14): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (14, 14): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (14, 15): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (15, 15): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (15, 16): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (16, 16): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (16, 17): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (17, 17): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (17, 18): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (18, 18): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (18, 19): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (19, 19): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (19, 20): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (20, 20): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (20, 21): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (21, 21): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (21, 22): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (22, 22): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (22, 23): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (23, 23): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (23, 24): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (24, 24): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (24, 25): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (25, 25): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (25, 26): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (26, 26): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (26, 27): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (27, 27): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (27, 28): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (28, 28): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (28, 29): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (29, 29): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (29, 30): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (30, 30): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (30, 31): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (31, 31): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (31, 32): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (32, 32): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (32, 33): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (33, 33): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (33, 34): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (34, 34): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (34, 35): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (35, 35): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (35, 36): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (36, 36): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (36, 37): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (37, 37): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (37, 38): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (38, 38): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (38, 39): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (39, 39): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (39, 40): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (40, 40): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (40, 41): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (41, 41): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (41, 42): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (42, 42): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (42, 43): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (43, 43): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (43, 44): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (44, 44): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (44, 45): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (45, 45): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (45, 46): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (46, 46): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (46, 47): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (47, 47): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (47, 48): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (48, 48): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (48, 49): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (49, 49): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (49, 50): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (50, 50): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (50, 51): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (51, 51): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (51, 52): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (52, 52): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (52, 53): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (53, 53): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (53, 54): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (54, 54): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (54, 55): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (55, 55): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (55, 56): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (56, 56): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (56, 57): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (57, 57): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (57, 58): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (58, 58): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (58, 59): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (59, 59): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (59, 60): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (60, 60): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (60, 61): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (61, 61): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (61, 62): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (62, 62): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (62, 63): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (63, 63): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (63, 64): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (64, 64): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (64, 65): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (65, 65): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (65, 66): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (66, 66): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (66, 67): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (67, 67): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (67, 68): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (68, 68): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (68, 69): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (69, 69): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (69, 70): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (70, 70): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (70, 71): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (71, 71): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (71, 72): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (72, 72): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (72, 73): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (73, 73): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (73, 74): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (74, 74): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (74, 75): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (75, 75): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (75, 76): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (76, 76): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (76, 77): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (77, 77): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (77, 78): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (78, 78): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (78, 79): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (79, 79): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (79, 80): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (80, 80): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (80, 81): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (81, 81): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (81, 82): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (82, 82): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (82, 83): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (83, 83): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (83, 84): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (84, 84): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (84, 85): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (85, 85): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (85, 86): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (86, 86): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (86, 87): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (87, 87): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (87, 88): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (88, 88): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (88, 89): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (89, 89): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (89, 90): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (90, 90): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (90, 91): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (91, 91): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (91, 92): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (92, 92): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (92, 93): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (93, 93): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (93, 94): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (94, 94): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (94, 95): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (95, 95): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (95, 96): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (96, 96): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (96, 97): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (97, 97): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (97, 98): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (98, 98): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (98, 99): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (99, 99): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (99, 100): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (100, 100): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (100, 101): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (101, 101): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (101, 102): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (102, 102): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (102, 103): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (103, 103): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (103, 104): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (104, 104): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (104, 105): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (105, 105): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (105, 106): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (106, 106): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (106, 107): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (107, 107): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (107, 108): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (108, 108): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (108, 109): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (109, 109): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (109, 110): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (110, 110): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (110, 111): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (111, 111): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (111, 112): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (112, 112): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (112, 113): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (113, 113): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (113, 114): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (114, 114): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (114, 115): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (115, 115): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (115, 116): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (116, 116): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (116, 117): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (117, 117): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (117, 118): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (118, 118): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (118, 119): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (119, 119): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (119, 120): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (120, 120): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (120, 121): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (121, 121): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (121, 122): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (122, 122): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (122, 123): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (123, 123): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (123, 124): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (124, 124): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (124, 125): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (125, 125): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (125, 126): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (126, 126): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (126, 127): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (127, 127): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (127, 128): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (128, 128): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (128, 129): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (129, 129): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (129, 130): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (130, 130): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (130, 131): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (131, 131): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (131, 132): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (132, 132): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (132, 133): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (133, 133): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (133, 134): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (134, 134): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (134, 135): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (135, 135): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (135, 136): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (136, 136): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (136, 137): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (137, 137): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (137, 138): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (138, 138): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (138, 139): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (139, 139): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (139, 140): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (140, 140): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (140, 141): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (141, 141): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (141, 142): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (142, 142): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (142, 143): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (143, 143): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (143, 144): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (144, 144): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (144, 145): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (145, 145): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (145, 146): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (146, 146): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (146, 147): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (147, 147): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (147, 148): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (148, 148): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (148, 149): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (149, 149): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (149, 150): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (150, 150): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (150, 151): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (151, 151): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (151, 152): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (152, 152): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (152, 153): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (153, 153): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (153, 154): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (154, 154): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (154, 155): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (155, 155): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (155, 156): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (156, 156): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (156, 157): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (157, 157): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (157, 158): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (158, 158): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (158, 159): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (159, 159): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (159, 160): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (160, 160): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (160, 161): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (161, 161): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (161, 162): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (162, 162): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (162, 163): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (163, 163): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (163, 164): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (164, 164): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (164, 165): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (165, 165): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (165, 166): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (166, 166): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (166, 167): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (167, 167): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (167, 168): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (168, 168): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (168, 169): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (169, 169): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (169, 170): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (170, 170): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (170, 171): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (171, 171): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (171, 172): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (172, 172): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (172, 173): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (173, 173): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (173, 174): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (174, 174): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (174, 175): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (175, 175): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (175, 176): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (176, 176): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (176, 177): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (177, 177): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (177, 178): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (178, 178): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (178, 179): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (179, 179): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (179, 180): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (180, 180): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (180, 181): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (181, 181): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (181, 182): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (182, 182): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (182, 183): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (183, 183): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (183, 184): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (184, 184): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (184, 185): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (185, 185): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (185, 186): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (186, 186): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (186, 187): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (187, 187): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (187, 188): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (188, 188): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (188, 189): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (189, 189): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (189, 190): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (190, 190): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (190, 191): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (191, 191): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (191, 192): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (192, 192): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (192, 193): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (193, 193): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (193, 194): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (194, 194): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (194, 195): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (195, 195): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (195, 196): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (196, 196): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (196, 197): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (197, 197): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (197, 198): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (198, 198): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (198, 199): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (199, 199): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (199, 200): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (200, 200): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (200, 201): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (201, 201): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (201, 202): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (202, 202): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (202, 203): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (203, 203): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (203, 204): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (204, 204): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (204, 205): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (205, 205): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (205, 206): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (206, 206): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (206, 207): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (207, 207): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (207, 208): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (208, 208): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (208, 209): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (209, 209): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (209, 210): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (210, 210): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (210, 211): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (211, 211): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (211, 212): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (212, 212): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (212, 213): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (213, 213): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (213, 214): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (214, 214): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (214, 215): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (215, 215): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (215, 216): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (216, 216): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (216, 217): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (217, 217): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (217, 218): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (218, 218): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (218, 219): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (219, 219): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (219, 220): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (220, 220): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (220, 221): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (221, 221): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (221, 222): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (222, 222): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (222, 223): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (223, 223): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (223, 224): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (224, 224): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (224, 225): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (225, 225): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (225, 226): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (226, 226): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (226, 227): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (227, 227): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (227, 228): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (228, 228): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (228, 229): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Span (229, 229): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Conversion en liste pour un affichage plus lisible\n",
    "binary_span_scores_list = masked_binary_span_scores.cpu().numpy().tolist()\n",
    "\n",
    "# Affichage structuré avec les spans associés\n",
    "print(\"Binary Span Scores with Spans:\")\n",
    "for i, example in enumerate(binary_span_scores_list):  # Pour chaque exemple dans le batch\n",
    "    print(f\"Example {i + 1}:\")\n",
    "    for j, span_scores in enumerate(example):  # Pour chaque span dans l'exemple\n",
    "        associated_span = spans[j]  # Associer le span avec l'indice\n",
    "        print(f\"Span {associated_span}: {span_scores}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vincentorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
