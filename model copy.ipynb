{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Exemple traité ===\n",
      "Tokenized Text:\n",
      "['Q', ':', 'Position', 'character', 'based', 'on', 'enemy', 'coordinates', 'in', 'lua', 'I', 'have', 'written', 'a', 'function', 'here', 'which', 'should', 'turn', 'my', 'character', 'based', 'on', 'enemy', 'coordinates', 'but', 'it', \"'\", 's', 'not', 'perfect', 'because', 'it', 'does', 'not', 'always', 'turn', 'where', 'I', 'want', 'it', 'to', 'and', 'perhaps', 'there', 'is', 'a', 'better', 'way', 'of', 'writing', 'it', 'local', 'myPosition', '=', '{', 'x', '=', '350', ',', 'y', '=', '355', '}', 'local', 'enemyPosition', '=', '{', 'x', '=', '352', ',', 'y', '=', '354', '}', 'local', 'xValue', ',', 'yValue', ',', 'xDir', ',', 'yDir', ',', 'dir', 'if', 'myPosition', '.', 'x', '>', 'enemyPosition', '.', 'x', 'then', 'xValue', '=', 'myPosition', '.', 'x', '-', 'enemyPosition', '.', 'x', 'elseif', 'myPosition', '.', 'x', '<', 'enemyPosition', '.', 'x', 'then', 'xValue', '=', 'myPosition', '.', 'x', '-', 'enemyPosition', '.', 'x', 'else', 'xValue', '=', '0', 'end', 'if', 'myPosition', '.', 'y', '>', 'enemyPosition', '.', 'y', 'then', 'yValue', '=', 'myPosition', '.', 'y', '-', 'enemyPosition', '.', 'y', 'elseif', 'myPosition', '.', 'y', '<', 'enemyPosition', '.', 'y', 'then', 'yValue', '=', 'myPosition', '.', 'y', '-', 'enemyPosition', '.', 'y', 'else', 'yValue', '=', '0', 'end', 'if', 'xValue', '<', '0', 'then', 'xDir', '=', '\"', 'TURN', 'RIGHT', '\"', 'elseif', 'xValue', '>', '0', 'then', 'xDir', '=', '\"', 'TURN', 'LEFT', '\"', 'end', 'if', 'yValue', '<', '0', 'then', 'yDir', '=', '\"', 'TURN', 'DOWN', '\"', 'elseif', 'yValue', '>', '0', 'then', 'yDir', '=', '\"', 'TURN', 'UP', '\"', 'end', 'if', 'xValue', '>', 'yValue', 'then', 'dir', '=', 'xDir', 'elseif', 'xValue', 'dir', '=', 'yDir', 'end', 'print', '(', '\"', 'Turn', ':', '\"', '.', '.', 'dir', ')', 'And', 'here', 'you', 'have', 'some', 'pictures', 'to', 'further', 'illustrate', 'what', 'I', 'have', 'in', 'mind', ':', 'As', 'you', 'can', 'see', 'on', 'the', 'pictures', ',', 'direction', 'depends', 'on', 'the', 'higher', 'number', '.']\n",
      "\n",
      "NER Spans:\n",
      " - Start: 14, End: 14, Entity Type: programming concept\n",
      " - Start: 9, End: 9, Entity Type: programming language\n",
      " - Start: 53, End: 53, Entity Type: variable\n",
      " - Start: 87, End: 87, Entity Type: variable\n",
      " - Start: 97, End: 97, Entity Type: variable\n",
      " - Start: 105, End: 105, Entity Type: variable\n",
      " - Start: 115, End: 115, Entity Type: variable\n",
      " - Start: 128, End: 128, Entity Type: variable\n",
      " - Start: 138, End: 138, Entity Type: variable\n",
      " - Start: 146, End: 146, Entity Type: variable\n",
      " - Start: 156, End: 156, Entity Type: variable\n",
      " - Start: 65, End: 65, Entity Type: variable\n",
      " - Start: 91, End: 91, Entity Type: variable\n",
      " - Start: 101, End: 101, Entity Type: variable\n",
      " - Start: 109, End: 109, Entity Type: variable\n",
      " - Start: 119, End: 119, Entity Type: variable\n",
      " - Start: 132, End: 132, Entity Type: variable\n",
      " - Start: 142, End: 142, Entity Type: variable\n",
      " - Start: 150, End: 150, Entity Type: variable\n",
      " - Start: 160, End: 160, Entity Type: variable\n",
      " - Start: 77, End: 77, Entity Type: variable\n",
      " - Start: 95, End: 95, Entity Type: variable\n",
      " - Start: 113, End: 113, Entity Type: variable\n",
      " - Start: 123, End: 123, Entity Type: variable\n",
      " - Start: 169, End: 169, Entity Type: variable\n",
      " - Start: 180, End: 180, Entity Type: variable\n",
      " - Start: 215, End: 215, Entity Type: variable\n",
      " - Start: 223, End: 223, Entity Type: variable\n",
      " - Start: 79, End: 79, Entity Type: variable\n",
      " - Start: 136, End: 136, Entity Type: variable\n",
      " - Start: 154, End: 154, Entity Type: variable\n",
      " - Start: 164, End: 164, Entity Type: variable\n",
      " - Start: 192, End: 192, Entity Type: variable\n",
      " - Start: 203, End: 203, Entity Type: variable\n",
      " - Start: 217, End: 217, Entity Type: variable\n",
      " - Start: 81, End: 81, Entity Type: variable\n",
      " - Start: 173, End: 173, Entity Type: variable\n",
      " - Start: 184, End: 184, Entity Type: variable\n",
      " - Start: 221, End: 221, Entity Type: variable\n",
      " - Start: 83, End: 83, Entity Type: variable\n",
      " - Start: 196, End: 196, Entity Type: variable\n",
      " - Start: 207, End: 207, Entity Type: variable\n",
      " - Start: 226, End: 226, Entity Type: variable\n",
      " - Start: 85, End: 85, Entity Type: variable\n",
      " - Start: 219, End: 219, Entity Type: variable\n",
      " - Start: 224, End: 224, Entity Type: variable\n",
      " - Start: 236, End: 236, Entity Type: variable\n",
      "\n",
      "Negative Entities:\n",
      "['database', 'Date']\n"
     ]
    }
   ],
   "source": [
    "# Charger les données traitées pour inspection\n",
    "with open('pilener_train.json', 'r') as f:\n",
    "    processed_data = json.load(f)\n",
    "\n",
    "# Afficher un exemple\n",
    "example_idx = 0  # Modifier cet indice pour voir d'autres exemples\n",
    "example = processed_data[example_idx]\n",
    "\n",
    "# Afficher avec une mise en forme claire\n",
    "print(\"=== Exemple traité ===\")\n",
    "print(\"Tokenized Text:\")\n",
    "print(example['tokenized_text'])\n",
    "print(\"\\nNER Spans:\")\n",
    "for span in example['ner']:\n",
    "    print(f\" - Start: {span[0]}, End: {span[1]}, Entity Type: {span[2]}\")\n",
    "print(\"\\nNegative Entities:\")\n",
    "print(example['negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\doria\\anaconda3\\envs\\vincentorch\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\Users\\doria\\anaconda3\\envs\\vincentorch\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GLiNER(\n",
       "  (encoder): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (entity_ffn): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (span_ffn): Sequential(\n",
       "    (0): Linear(in_features=1536, out_features=768, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (sigmoid): Sigmoid()\n",
       "  (loss_fn): BCELoss()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GLiNER(pretrained_model_name=\"microsoft/deberta-v3-base\", span_max_length=2, hidden_size=768)\n",
    "# Initialiser le modèle\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Data:   0%|          | 0/45889 [00:00<?, ?entry/s]Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Processing Data:  10%|▉         | 4388/45889 [00:14<02:11, 315.66entry/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error, not same size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Data:  34%|███▍      | 15513/45889 [00:51<01:33, 324.96entry/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error, not same size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Data:  38%|███▊      | 17454/45889 [00:57<01:29, 317.02entry/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error, not same size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Data:  53%|█████▎    | 24213/45889 [01:19<01:11, 303.56entry/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error, not same size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Data:  64%|██████▍   | 29373/45889 [01:36<00:51, 322.03entry/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error, not same size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Data:  73%|███████▎  | 33394/45889 [01:49<00:39, 312.62entry/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error, not same size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Data:  76%|███████▌  | 34905/45889 [01:54<00:35, 312.34entry/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error, not same size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Data:  88%|████████▊ | 40338/45889 [02:12<00:17, 324.67entry/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error, not same size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Data: 100%|██████████| 45889/45889 [02:30<00:00, 305.74entry/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "def prepare_data_for_training(processed_data, model, max_length=512):\n",
    "    input_ids, labels, entity_tensors, attention_masks = [], [], [], []\n",
    "\n",
    "    # Créer un mapping des types d'entités vers des entiers\n",
    "    entity_types = {entity for entry in processed_data for _, _, entity in entry[\"ner\"]}\n",
    "    # Ajouter chaque type d'entité comme un token spécial dans le tokenizer\n",
    "    special_tokens = [f\"[ENT] {entity}\" for entity in entity_types]\n",
    "    model.tokenizer.add_special_tokens({\"additional_special_tokens\": special_tokens})\n",
    "    model.encoder.resize_token_embeddings(len(model.tokenizer))\n",
    "\n",
    "    for entry in tqdm(processed_data, desc=\"Processing Data\", unit=\"entry\"):\n",
    "        tokenized_text = entry[\"tokenized_text\"]\n",
    "        ner_spans = entry[\"ner\"]\n",
    "                \n",
    "        # Générer le tensor de labels\n",
    "        label_tensor = torch.zeros(max_length, dtype=torch.long)\n",
    "        \n",
    "        # Collecter les entités uniques pour l'entrée actuelle\n",
    "        current_entity_id = []\n",
    "        current_entity_str = []\n",
    "        \n",
    "        for start, end, entity_type in ner_spans:\n",
    "            if start < max_length and end < max_length:\n",
    "                entity_token_id = model.tokenizer.convert_tokens_to_ids(f'[ENT] {entity_type}')\n",
    "\n",
    "                label_tensor[start:end + 1] = entity_token_id\n",
    "                \n",
    "                if entity_token_id not in current_entity_id:\n",
    "                    current_entity_id.append(entity_token_id)  # Ajouter le nombre de tokens\n",
    "                \n",
    "                if entity_type not in current_entity_str:\n",
    "                    current_entity_str.append(entity_type)  # Ajouter le type d'entité en clair\n",
    "\n",
    "        # Ajouter les entités comme préfixe à la séquence\n",
    "        entity_tokens = \" \".join(f\"[ENT] {et}\" for et in current_entity_str)\n",
    "        \n",
    "        # Tokenizer la séquence complète\n",
    "        encoded = model.tokenizer(\n",
    "            tokenized_text, return_tensors=\"pt\", padding=\"max_length\", truncation=True,is_split_into_words=True, add_special_tokens=False\n",
    "        )\n",
    "\n",
    "        # Récupération des IDs des mots (chaque sous-token est associé à un mot original)\n",
    "        word_ids = encoded.word_ids()\n",
    "\n",
    "        # Filtrage pour ne conserver que les IDs des premiers sous-tokens de chaque mot\n",
    "        first_subtoken_ids = [\n",
    "            encoded[\"input_ids\"][0, i].item() for i, word_id in enumerate(word_ids) if word_id is not None and (i == 0 or word_ids[i - 1] != word_id)\n",
    "        ]\n",
    "\n",
    "        encoded_entity = model.tokenizer(\n",
    "            entity_tokens, return_tensors=\"pt\", padding=\"max_length\", truncation=True,is_split_into_words=False, add_special_tokens=False\n",
    "        )\n",
    "\n",
    "        if(len(current_entity_str) != len(encoded_entity[\"input_ids\"][0]) or \n",
    "           len(tokenized_text) != len(first_subtoken_ids)) :\n",
    "            print(\"error, not same size\")\n",
    "            continue\n",
    "        \n",
    "        sep_id = model.tokenizer.convert_tokens_to_ids(f'[SEP]')\n",
    "\n",
    "        combined_ids = (\n",
    "            encoded_entity[\"input_ids\"][0].tolist() +  # Convertir en liste\n",
    "            [sep_id] +  # Ajouter le token [SEP]\n",
    "            first_subtoken_ids  # Ajouter les premiers sous-tokens\n",
    "        )\n",
    "\n",
    "        if(len(combined_ids) != (len(encoded_entity[\"input_ids\"][0]) + len(first_subtoken_ids) + 1)):\n",
    "            print(\"error, not same size\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        # S'assurer que toutes les séquences sont de la même taille\n",
    "        combined_ids = combined_ids[:max_length]  # Tronquer si nécessaire\n",
    "        combined_ids += [0] * (max_length - len(combined_ids))  # Ajouter du padding si nécessaire\n",
    "\n",
    "        # Créer l'attention mask\n",
    "        attention_mask = [1] * len(combined_ids) + [0] * (max_length - len(combined_ids))\n",
    "\n",
    "        # Convertir les entités en un tensor\n",
    "        entity_tensor = torch.tensor(current_entity_id, dtype=torch.long)\n",
    "        \n",
    "        # Ajouter les données tokenisées, les labels et les attention masks\n",
    "        input_ids.append(torch.tensor(combined_ids, dtype=torch.long))\n",
    "        labels.append(label_tensor)\n",
    "        entity_tensors.append(entity_tensor)\n",
    "        attention_masks.append(torch.tensor(attention_mask, dtype=torch.long))\n",
    "\n",
    "    return torch.stack(input_ids), torch.stack(labels), entity_tensors, torch.stack(attention_masks)\n",
    "\n",
    "\n",
    "# Charger les données générées précédemment\n",
    "with open('pilener_train.json', 'r') as f:\n",
    "    processed_data = json.load(f)\n",
    "\n",
    "# Préparer les données avec suivi d'avancement\n",
    "input_ids, labels, entity_tensors, attention_masks = prepare_data_for_training(processed_data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143177\n",
      "45881\n",
      "45881\n"
     ]
    }
   ],
   "source": [
    "print(len(model.tokenizer))\n",
    "print(len(input_ids))\n",
    "print(len(entity_tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme de input_ids : torch.Size([45881, 512])\n",
      "Forme de attention_masks : torch.Size([45881, 512])\n",
      "Forme de labels : torch.Size([45881, 512])\n",
      "\n",
      "Exemple de input_ids (première entrée) :\n",
      "tensor([133419, 132993, 138831,      2,   1729,    877,  18172,   1470,    636,\n",
      "           277,   4648,  14321,    267,  96792,    273,    286,   1223,    266,\n",
      "          1571,    422,    319,    403,    930,    312,   1470,    636,    277,\n",
      "          4648,  14321,    304,    278,    382,   1550,    298,    801,    401,\n",
      "           278,    490,    298,    489,    930,    399,    273,    409,    278,\n",
      "           264,    263,   1733,    343,    269,    266,    493,    384,    265,\n",
      "           898,    278,    588,    312,   1842,  13856,   1204,   1842,   7351,\n",
      "           366,   2982,   1842,  40059,  15805,    588,   4648,   1842,  13856,\n",
      "          1204,   1842,  42091,    366,   2982,   1842,  50238,  15805,    588,\n",
      "          1204,    366,   2982,    366,   1204,    366,   2982,    366,  30791,\n",
      "           337,    312,    323,   1204,   2108,   4648,    323,   1204,    393,\n",
      "          1204,   1842,    312,    323,   1204,    341,   4648,    323,   1204,\n",
      "           995,    312,    323,   1204,   2569,   4648,    323,   1204,    393,\n",
      "          1204,   1842,    312,    323,   1204,    341,   4648,    323,   1204,\n",
      "           995,   1204,   1842,    767,    513,    337,    312,    323,   2982,\n",
      "          2108,   4648,    323,   2982,    393,   2982,   1842,    312,    323,\n",
      "          2982,    341,   4648,    323,   2982,    995,    312,    323,   2982,\n",
      "          2569,   4648,    323,   2982,    393,   2982,   1842,    312,    323,\n",
      "          2982,    341,   4648,    323,   2982,    995,   2982,   1842,    767,\n",
      "           513,    337,   1204,   2569,    767,    393,   1204,   1842,    307,\n",
      "         47334,  21171,    307,    995,   1204,   2108,    767,    393,   1204,\n",
      "          1842,    307,  47334,  43424,    307,    513,    337,   2982,   2569,\n",
      "           767,    393,   2982,   1842,    307,  47334,  27920,    307,    995,\n",
      "          2982,   2108,    767,    393,   2982,   1842,    307,  47334,   9146,\n",
      "           307,    513,    337,   1204,   2108,   2982,    393,  30791,   1842,\n",
      "          1204,    995,   1204,  30791,   1842,   2982,    513,   2118,    287,\n",
      "           307,   6930,    877,    307,    323,    323,  30791,   1263,    414,\n",
      "           422,    274,    286,    347,   1631,    264,    839,  10756,    339,\n",
      "           273,    286,    267,    791,    877,    463,    274,    295,    398,\n",
      "           277,    262,   1631,    366,   1983,   3898,    277,    262,   1026,\n",
      "           496,    323,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0])\n",
      "\n",
      "Exemple de attention_masks (première entrée) :\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Exemple de labels (première entrée) :\n",
      "tensor([     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "        132993,      0,      0,      0,      0, 133419,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0, 138831,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0, 138831,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0, 138831,      0, 138831,      0,\n",
      "        138831,      0, 138831,      0, 138831,      0, 138831,      0,      0,\n",
      "             0, 138831,      0,      0,      0, 138831,      0, 138831,      0,\n",
      "             0,      0, 138831,      0,      0,      0, 138831,      0,      0,\n",
      "             0, 138831,      0,      0,      0, 138831,      0, 138831,      0,\n",
      "             0,      0, 138831,      0,      0,      0, 138831,      0,      0,\n",
      "             0,      0, 138831,      0,      0,      0, 138831,      0,      0,\n",
      "             0, 138831,      0, 138831,      0,      0,      0, 138831,      0,\n",
      "             0,      0, 138831,      0,      0,      0, 138831,      0,      0,\n",
      "             0, 138831,      0, 138831,      0,      0,      0, 138831,      0,\n",
      "             0,      0, 138831,      0,      0,      0,      0, 138831,      0,\n",
      "             0,      0, 138831,      0,      0,      0,      0,      0,      0,\n",
      "        138831,      0,      0,      0, 138831,      0,      0,      0,      0,\n",
      "             0,      0,      0, 138831,      0,      0,      0, 138831,      0,\n",
      "             0,      0,      0,      0,      0, 138831,      0,      0,      0,\n",
      "        138831,      0,      0,      0,      0,      0,      0,      0, 138831,\n",
      "             0, 138831,      0, 138831,      0, 138831,      0, 138831, 138831,\n",
      "             0, 138831,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0, 138831,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0])\n",
      "\n",
      "Exemple de entity_tensors (première entrée) :\n",
      "tensor([133419, 132993, 138831])\n"
     ]
    }
   ],
   "source": [
    "# Afficher les formes des tensors principaux\n",
    "print(f\"Forme de input_ids : {input_ids.shape}\")\n",
    "print(f\"Forme de attention_masks : {attention_masks.shape}\")\n",
    "print(f\"Forme de labels : {labels.shape}\")\n",
    "\n",
    "# Afficher un exemple pour les tensors principaux\n",
    "print(\"\\nExemple de input_ids (première entrée) :\")\n",
    "print(input_ids[0])\n",
    "\n",
    "print(\"\\nExemple de attention_masks (première entrée) :\")\n",
    "print(attention_masks[0])\n",
    "\n",
    "print(\"\\nExemple de labels (première entrée) :\")\n",
    "print(labels[0])\n",
    "\n",
    "# Afficher un exemple pour les entity_tensors\n",
    "print(\"\\nExemple de entity_tensors (première entrée) :\")\n",
    "print(entity_tensors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torch\n",
    "\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(self, input_ids, attention_masks, labels, entities, max_span_length=2):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_masks = attention_masks\n",
    "        self.labels = labels  # Liste des labels pour chaque token\n",
    "        self.entities = entities  # Liste des entités uniques\n",
    "        self.max_span_length = max_span_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_id = self.input_ids[idx]\n",
    "        attention_mask = self.attention_masks[idx]\n",
    "        token_labels = self.labels[idx]  # Labels token-par-token\n",
    "        entity_ids = self.entities[idx]  # Entités pour cet exemple\n",
    "\n",
    "        num_tokens = len(input_id) - len(entity_ids) - 1\n",
    "        spans = [\n",
    "            (start, end)\n",
    "            for start in range(num_tokens)\n",
    "            for end in range(start, min(start + self.max_span_length, num_tokens))\n",
    "        ]\n",
    "        num_spans = len(spans)\n",
    "        num_entities = len(entity_ids)\n",
    "\n",
    "        # Matrice binaire : spans x entities\n",
    "        binary_labels = torch.zeros(num_spans, num_entities, dtype=torch.float)\n",
    "\n",
    "        for span_idx, (start, end) in enumerate(spans):\n",
    "            span_labels = token_labels[start:end + 1]\n",
    "            for entity_idx, entity_id in enumerate(entity_ids):\n",
    "                if all(label == entity_id for label in span_labels):\n",
    "                    binary_labels[span_idx, entity_idx] = 1\n",
    "\n",
    "        return input_id, attention_mask, spans, entity_ids, binary_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = int(len(input_ids) * proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input ID: tensor([133419, 132993, 138831,      2,   1729,    877,  18172,   1470,    636,\n",
      "           277,   4648,  14321,    267,  96792,    273,    286,   1223,    266,\n",
      "          1571,    422,    319,    403,    930,    312,   1470,    636,    277,\n",
      "          4648,  14321,    304,    278,    382,   1550,    298,    801,    401,\n",
      "           278,    490,    298,    489,    930,    399,    273,    409,    278,\n",
      "           264,    263,   1733,    343,    269,    266,    493,    384,    265,\n",
      "           898,    278,    588,    312,   1842,  13856,   1204,   1842,   7351,\n",
      "           366,   2982,   1842,  40059,  15805,    588,   4648,   1842,  13856,\n",
      "          1204,   1842,  42091,    366,   2982,   1842,  50238,  15805,    588,\n",
      "          1204,    366,   2982,    366,   1204,    366,   2982,    366,  30791,\n",
      "           337,    312,    323,   1204,   2108,   4648,    323,   1204,    393,\n",
      "          1204,   1842,    312,    323,   1204,    341,   4648,    323,   1204,\n",
      "           995,    312,    323,   1204,   2569,   4648,    323,   1204,    393,\n",
      "          1204,   1842,    312,    323,   1204,    341,   4648,    323,   1204,\n",
      "           995,   1204,   1842,    767,    513,    337,    312,    323,   2982,\n",
      "          2108,   4648,    323,   2982,    393,   2982,   1842,    312,    323,\n",
      "          2982,    341,   4648,    323,   2982,    995,    312,    323,   2982,\n",
      "          2569,   4648,    323,   2982,    393,   2982,   1842,    312,    323,\n",
      "          2982,    341,   4648,    323,   2982,    995,   2982,   1842,    767,\n",
      "           513,    337,   1204,   2569,    767,    393,   1204,   1842,    307,\n",
      "         47334,  21171,    307,    995,   1204,   2108,    767,    393,   1204,\n",
      "          1842,    307,  47334,  43424,    307,    513,    337,   2982,   2569,\n",
      "           767,    393,   2982,   1842,    307,  47334,  27920,    307,    995,\n",
      "          2982,   2108,    767,    393,   2982,   1842,    307,  47334,   9146,\n",
      "           307,    513,    337,   1204,   2108,   2982,    393,  30791,   1842,\n",
      "          1204,    995,   1204,  30791,   1842,   2982,    513,   2118,    287,\n",
      "           307,   6930,    877,    307,    323,    323,  30791,   1263,    414,\n",
      "           422,    274,    286,    347,   1631,    264,    839,  10756,    339,\n",
      "           273,    286,    267,    791,    877,    463,    274,    295,    398,\n",
      "           277,    262,   1631,    366,   1983,   3898,    277,    262,   1026,\n",
      "           496,    323,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0])\n",
      "Spans: [(0, 0), (0, 1), (1, 1), (1, 2), (2, 2), (2, 3), (3, 3), (3, 4), (4, 4), (4, 5), (5, 5), (5, 6), (6, 6), (6, 7), (7, 7), (7, 8), (8, 8), (8, 9), (9, 9), (9, 10), (10, 10), (10, 11), (11, 11), (11, 12), (12, 12), (12, 13), (13, 13), (13, 14), (14, 14), (14, 15), (15, 15), (15, 16), (16, 16), (16, 17), (17, 17), (17, 18), (18, 18), (18, 19), (19, 19), (19, 20), (20, 20), (20, 21), (21, 21), (21, 22), (22, 22), (22, 23), (23, 23), (23, 24), (24, 24), (24, 25), (25, 25), (25, 26), (26, 26), (26, 27), (27, 27), (27, 28), (28, 28), (28, 29), (29, 29), (29, 30), (30, 30), (30, 31), (31, 31), (31, 32), (32, 32), (32, 33), (33, 33), (33, 34), (34, 34), (34, 35), (35, 35), (35, 36), (36, 36), (36, 37), (37, 37), (37, 38), (38, 38), (38, 39), (39, 39), (39, 40), (40, 40), (40, 41), (41, 41), (41, 42), (42, 42), (42, 43), (43, 43), (43, 44), (44, 44), (44, 45), (45, 45), (45, 46), (46, 46), (46, 47), (47, 47), (47, 48), (48, 48), (48, 49), (49, 49), (49, 50), (50, 50), (50, 51), (51, 51), (51, 52), (52, 52), (52, 53), (53, 53), (53, 54), (54, 54), (54, 55), (55, 55), (55, 56), (56, 56), (56, 57), (57, 57), (57, 58), (58, 58), (58, 59), (59, 59), (59, 60), (60, 60), (60, 61), (61, 61), (61, 62), (62, 62), (62, 63), (63, 63), (63, 64), (64, 64), (64, 65), (65, 65), (65, 66), (66, 66), (66, 67), (67, 67), (67, 68), (68, 68), (68, 69), (69, 69), (69, 70), (70, 70), (70, 71), (71, 71), (71, 72), (72, 72), (72, 73), (73, 73), (73, 74), (74, 74), (74, 75), (75, 75), (75, 76), (76, 76), (76, 77), (77, 77), (77, 78), (78, 78), (78, 79), (79, 79), (79, 80), (80, 80), (80, 81), (81, 81), (81, 82), (82, 82), (82, 83), (83, 83), (83, 84), (84, 84), (84, 85), (85, 85), (85, 86), (86, 86), (86, 87), (87, 87), (87, 88), (88, 88), (88, 89), (89, 89), (89, 90), (90, 90), (90, 91), (91, 91), (91, 92), (92, 92), (92, 93), (93, 93), (93, 94), (94, 94), (94, 95), (95, 95), (95, 96), (96, 96), (96, 97), (97, 97), (97, 98), (98, 98), (98, 99), (99, 99), (99, 100), (100, 100), (100, 101), (101, 101), (101, 102), (102, 102), (102, 103), (103, 103), (103, 104), (104, 104), (104, 105), (105, 105), (105, 106), (106, 106), (106, 107), (107, 107), (107, 108), (108, 108), (108, 109), (109, 109), (109, 110), (110, 110), (110, 111), (111, 111), (111, 112), (112, 112), (112, 113), (113, 113), (113, 114), (114, 114), (114, 115), (115, 115), (115, 116), (116, 116), (116, 117), (117, 117), (117, 118), (118, 118), (118, 119), (119, 119), (119, 120), (120, 120), (120, 121), (121, 121), (121, 122), (122, 122), (122, 123), (123, 123), (123, 124), (124, 124), (124, 125), (125, 125), (125, 126), (126, 126), (126, 127), (127, 127), (127, 128), (128, 128), (128, 129), (129, 129), (129, 130), (130, 130), (130, 131), (131, 131), (131, 132), (132, 132), (132, 133), (133, 133), (133, 134), (134, 134), (134, 135), (135, 135), (135, 136), (136, 136), (136, 137), (137, 137), (137, 138), (138, 138), (138, 139), (139, 139), (139, 140), (140, 140), (140, 141), (141, 141), (141, 142), (142, 142), (142, 143), (143, 143), (143, 144), (144, 144), (144, 145), (145, 145), (145, 146), (146, 146), (146, 147), (147, 147), (147, 148), (148, 148), (148, 149), (149, 149), (149, 150), (150, 150), (150, 151), (151, 151), (151, 152), (152, 152), (152, 153), (153, 153), (153, 154), (154, 154), (154, 155), (155, 155), (155, 156), (156, 156), (156, 157), (157, 157), (157, 158), (158, 158), (158, 159), (159, 159), (159, 160), (160, 160), (160, 161), (161, 161), (161, 162), (162, 162), (162, 163), (163, 163), (163, 164), (164, 164), (164, 165), (165, 165), (165, 166), (166, 166), (166, 167), (167, 167), (167, 168), (168, 168), (168, 169), (169, 169), (169, 170), (170, 170), (170, 171), (171, 171), (171, 172), (172, 172), (172, 173), (173, 173), (173, 174), (174, 174), (174, 175), (175, 175), (175, 176), (176, 176), (176, 177), (177, 177), (177, 178), (178, 178), (178, 179), (179, 179), (179, 180), (180, 180), (180, 181), (181, 181), (181, 182), (182, 182), (182, 183), (183, 183), (183, 184), (184, 184), (184, 185), (185, 185), (185, 186), (186, 186), (186, 187), (187, 187), (187, 188), (188, 188), (188, 189), (189, 189), (189, 190), (190, 190), (190, 191), (191, 191), (191, 192), (192, 192), (192, 193), (193, 193), (193, 194), (194, 194), (194, 195), (195, 195), (195, 196), (196, 196), (196, 197), (197, 197), (197, 198), (198, 198), (198, 199), (199, 199), (199, 200), (200, 200), (200, 201), (201, 201), (201, 202), (202, 202), (202, 203), (203, 203), (203, 204), (204, 204), (204, 205), (205, 205), (205, 206), (206, 206), (206, 207), (207, 207), (207, 208), (208, 208), (208, 209), (209, 209), (209, 210), (210, 210), (210, 211), (211, 211), (211, 212), (212, 212), (212, 213), (213, 213), (213, 214), (214, 214), (214, 215), (215, 215), (215, 216), (216, 216), (216, 217), (217, 217), (217, 218), (218, 218), (218, 219), (219, 219), (219, 220), (220, 220), (220, 221), (221, 221), (221, 222), (222, 222), (222, 223), (223, 223), (223, 224), (224, 224), (224, 225), (225, 225), (225, 226), (226, 226), (226, 227), (227, 227), (227, 228), (228, 228), (228, 229), (229, 229), (229, 230), (230, 230), (230, 231), (231, 231), (231, 232), (232, 232), (232, 233), (233, 233), (233, 234), (234, 234), (234, 235), (235, 235), (235, 236), (236, 236), (236, 237), (237, 237), (237, 238), (238, 238), (238, 239), (239, 239), (239, 240), (240, 240), (240, 241), (241, 241), (241, 242), (242, 242), (242, 243), (243, 243), (243, 244), (244, 244), (244, 245), (245, 245), (245, 246), (246, 246), (246, 247), (247, 247), (247, 248), (248, 248), (248, 249), (249, 249), (249, 250), (250, 250), (250, 251), (251, 251), (251, 252), (252, 252), (252, 253), (253, 253), (253, 254), (254, 254), (254, 255), (255, 255), (255, 256), (256, 256), (256, 257), (257, 257), (257, 258), (258, 258), (258, 259), (259, 259), (259, 260), (260, 260), (260, 261), (261, 261), (261, 262), (262, 262), (262, 263), (263, 263), (263, 264), (264, 264), (264, 265), (265, 265), (265, 266), (266, 266), (266, 267), (267, 267), (267, 268), (268, 268), (268, 269), (269, 269), (269, 270), (270, 270), (270, 271), (271, 271), (271, 272), (272, 272), (272, 273), (273, 273), (273, 274), (274, 274), (274, 275), (275, 275), (275, 276), (276, 276), (276, 277), (277, 277), (277, 278), (278, 278), (278, 279), (279, 279), (279, 280), (280, 280), (280, 281), (281, 281), (281, 282), (282, 282), (282, 283), (283, 283), (283, 284), (284, 284), (284, 285), (285, 285), (285, 286), (286, 286), (286, 287), (287, 287), (287, 288), (288, 288), (288, 289), (289, 289), (289, 290), (290, 290), (290, 291), (291, 291), (291, 292), (292, 292), (292, 293), (293, 293), (293, 294), (294, 294), (294, 295), (295, 295), (295, 296), (296, 296), (296, 297), (297, 297), (297, 298), (298, 298), (298, 299), (299, 299), (299, 300), (300, 300), (300, 301), (301, 301), (301, 302), (302, 302), (302, 303), (303, 303), (303, 304), (304, 304), (304, 305), (305, 305), (305, 306), (306, 306), (306, 307), (307, 307), (307, 308), (308, 308), (308, 309), (309, 309), (309, 310), (310, 310), (310, 311), (311, 311), (311, 312), (312, 312), (312, 313), (313, 313), (313, 314), (314, 314), (314, 315), (315, 315), (315, 316), (316, 316), (316, 317), (317, 317), (317, 318), (318, 318), (318, 319), (319, 319), (319, 320), (320, 320), (320, 321), (321, 321), (321, 322), (322, 322), (322, 323), (323, 323), (323, 324), (324, 324), (324, 325), (325, 325), (325, 326), (326, 326), (326, 327), (327, 327), (327, 328), (328, 328), (328, 329), (329, 329), (329, 330), (330, 330), (330, 331), (331, 331), (331, 332), (332, 332), (332, 333), (333, 333), (333, 334), (334, 334), (334, 335), (335, 335), (335, 336), (336, 336), (336, 337), (337, 337), (337, 338), (338, 338), (338, 339), (339, 339), (339, 340), (340, 340), (340, 341), (341, 341), (341, 342), (342, 342), (342, 343), (343, 343), (343, 344), (344, 344), (344, 345), (345, 345), (345, 346), (346, 346), (346, 347), (347, 347), (347, 348), (348, 348), (348, 349), (349, 349), (349, 350), (350, 350), (350, 351), (351, 351), (351, 352), (352, 352), (352, 353), (353, 353), (353, 354), (354, 354), (354, 355), (355, 355), (355, 356), (356, 356), (356, 357), (357, 357), (357, 358), (358, 358), (358, 359), (359, 359), (359, 360), (360, 360), (360, 361), (361, 361), (361, 362), (362, 362), (362, 363), (363, 363), (363, 364), (364, 364), (364, 365), (365, 365), (365, 366), (366, 366), (366, 367), (367, 367), (367, 368), (368, 368), (368, 369), (369, 369), (369, 370), (370, 370), (370, 371), (371, 371), (371, 372), (372, 372), (372, 373), (373, 373), (373, 374), (374, 374), (374, 375), (375, 375), (375, 376), (376, 376), (376, 377), (377, 377), (377, 378), (378, 378), (378, 379), (379, 379), (379, 380), (380, 380), (380, 381), (381, 381), (381, 382), (382, 382), (382, 383), (383, 383), (383, 384), (384, 384), (384, 385), (385, 385), (385, 386), (386, 386), (386, 387), (387, 387), (387, 388), (388, 388), (388, 389), (389, 389), (389, 390), (390, 390), (390, 391), (391, 391), (391, 392), (392, 392), (392, 393), (393, 393), (393, 394), (394, 394), (394, 395), (395, 395), (395, 396), (396, 396), (396, 397), (397, 397), (397, 398), (398, 398), (398, 399), (399, 399), (399, 400), (400, 400), (400, 401), (401, 401), (401, 402), (402, 402), (402, 403), (403, 403), (403, 404), (404, 404), (404, 405), (405, 405), (405, 406), (406, 406), (406, 407), (407, 407), (407, 408), (408, 408), (408, 409), (409, 409), (409, 410), (410, 410), (410, 411), (411, 411), (411, 412), (412, 412), (412, 413), (413, 413), (413, 414), (414, 414), (414, 415), (415, 415), (415, 416), (416, 416), (416, 417), (417, 417), (417, 418), (418, 418), (418, 419), (419, 419), (419, 420), (420, 420), (420, 421), (421, 421), (421, 422), (422, 422), (422, 423), (423, 423), (423, 424), (424, 424), (424, 425), (425, 425), (425, 426), (426, 426), (426, 427), (427, 427), (427, 428), (428, 428), (428, 429), (429, 429), (429, 430), (430, 430), (430, 431), (431, 431), (431, 432), (432, 432), (432, 433), (433, 433), (433, 434), (434, 434), (434, 435), (435, 435), (435, 436), (436, 436), (436, 437), (437, 437), (437, 438), (438, 438), (438, 439), (439, 439), (439, 440), (440, 440), (440, 441), (441, 441), (441, 442), (442, 442), (442, 443), (443, 443), (443, 444), (444, 444), (444, 445), (445, 445), (445, 446), (446, 446), (446, 447), (447, 447), (447, 448), (448, 448), (448, 449), (449, 449), (449, 450), (450, 450), (450, 451), (451, 451), (451, 452), (452, 452), (452, 453), (453, 453), (453, 454), (454, 454), (454, 455), (455, 455), (455, 456), (456, 456), (456, 457), (457, 457), (457, 458), (458, 458), (458, 459), (459, 459), (459, 460), (460, 460), (460, 461), (461, 461), (461, 462), (462, 462), (462, 463), (463, 463), (463, 464), (464, 464), (464, 465), (465, 465), (465, 466), (466, 466), (466, 467), (467, 467), (467, 468), (468, 468), (468, 469), (469, 469), (469, 470), (470, 470), (470, 471), (471, 471), (471, 472), (472, 472), (472, 473), (473, 473), (473, 474), (474, 474), (474, 475), (475, 475), (475, 476), (476, 476), (476, 477), (477, 477), (477, 478), (478, 478), (478, 479), (479, 479), (479, 480), (480, 480), (480, 481), (481, 481), (481, 482), (482, 482), (482, 483), (483, 483), (483, 484), (484, 484), (484, 485), (485, 485), (485, 486), (486, 486), (486, 487), (487, 487), (487, 488), (488, 488), (488, 489), (489, 489), (489, 490), (490, 490), (490, 491), (491, 491), (491, 492), (492, 492), (492, 493), (493, 493), (493, 494), (494, 494), (494, 495), (495, 495), (495, 496), (496, 496), (496, 497), (497, 497), (497, 498), (498, 498), (498, 499), (499, 499), (499, 500), (500, 500), (500, 501), (501, 501), (501, 502), (502, 502), (502, 503), (503, 503), (503, 504), (504, 504), (504, 505), (505, 505), (505, 506), (506, 506), (506, 507), (507, 507)]\n",
      "Entity IDs: tensor([133419, 132993, 138831])\n",
      "Binary Labels: tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Créer le dataset\n",
    "dataset = NERDataset(input_ids[:ind], attention_masks[:ind], labels[:ind], entity_tensors[:ind])\n",
    "\n",
    "# Exemple de récupération d'une entrée\n",
    "input_id, attention_mask, spans, entity_ids, binary_labels = dataset[0]\n",
    "\n",
    "print(\"Input ID:\", input_id)\n",
    "print(\"Spans:\", spans)\n",
    "print(\"Entity IDs:\", entity_ids)\n",
    "print(\"Binary Labels:\", binary_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids, attention_masks, spans, entity_ids, binary_labels = zip(*batch)\n",
    "\n",
    "    # Trouver les tailles maximales pour le padding\n",
    "    max_len = max(len(ids) for ids in input_ids)  # Longueur max des tokens\n",
    "    max_spans = max(len(s) for s in spans)  # Nombre max de spans\n",
    "    max_entities = max(len(e) for e in entity_ids)  # Nombre max d'entités\n",
    "\n",
    "    # Padding des input_ids et attention_masks\n",
    "    padded_input_ids = torch.stack([\n",
    "        torch.cat([ids, torch.zeros(max_len - len(ids), dtype=torch.long)])\n",
    "        for ids in input_ids\n",
    "    ])\n",
    "    padded_attention_masks = torch.stack([\n",
    "        torch.cat([mask, torch.zeros(max_len - len(mask), dtype=torch.long)])\n",
    "        for mask in attention_masks\n",
    "    ])\n",
    "\n",
    "    # Padding des spans\n",
    "    padded_spans = torch.stack([\n",
    "        torch.cat([torch.tensor(s, dtype=torch.long), torch.zeros((max_spans - len(s), 2), dtype=torch.long)])\n",
    "        for s in spans\n",
    "    ])\n",
    "\n",
    "    # Padding des entity_ids\n",
    "    padded_entity_ids = torch.stack([\n",
    "        torch.cat([e, torch.zeros(max_entities - len(e), dtype=torch.long)])\n",
    "        for e in entity_ids\n",
    "    ])\n",
    "\n",
    "    # Padding des binary_labels\n",
    "    padded_binary_labels = torch.stack([\n",
    "        torch.cat([\n",
    "            torch.cat([bl, torch.zeros(max_spans - bl.size(0), bl.size(1))], dim=0) if bl.size(0) < max_spans else bl,\n",
    "            torch.zeros(max_spans, max_entities - bl.size(1)) if bl.size(1) < max_entities else torch.zeros(0)\n",
    "        ], dim=1)\n",
    "        for bl in binary_labels\n",
    "    ])\n",
    "\n",
    "    return padded_input_ids, padded_attention_masks, padded_spans, padded_entity_ids, padded_binary_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2294\n",
      "Validation size: 287\n",
      "Test size: 287\n"
     ]
    }
   ],
   "source": [
    "# Définir les proportions pour le train, validation et test\n",
    "train_ratio = 0.8  # 80% des données pour l'entraînement\n",
    "val_ratio = 0.1    # 10% des données pour la validation\n",
    "test_ratio = 0.1   # 10% des données pour le test\n",
    "\n",
    "# Calculer les tailles des différents ensembles\n",
    "train_size = int(train_ratio * len(dataset))\n",
    "val_size = int(val_ratio * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "# Diviser les données en train, validation, et test\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Créer les DataLoaders pour chaque ensemble\n",
    "batch_size = 16  # Ajuster selon vos besoins\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "# Vérification des tailles\n",
    "print(f\"Train size: {len(train_loader)}\")\n",
    "print(f\"Validation size: {len(val_loader)}\")\n",
    "print(f\"Test size: {len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "class GLiNER(nn.Module):\n",
    "    def __init__(self, pretrained_model_name=\"microsoft/deberta-v3-base\", span_max_length=2, hidden_size=768):\n",
    "        super(GLiNER, self).__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "        self.encoder = AutoModel.from_pretrained(pretrained_model_name)\n",
    "\n",
    "        self.entity_ffn = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size)\n",
    "        )\n",
    "        \n",
    "        self.span_ffn = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size)\n",
    "        )\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.span_max_length = span_max_length\n",
    "        self.loss_fn = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "\n",
    "    def forward(self, input_ids, attention_masks, entity_types, spans, binary_labels=None):\n",
    "        # print(\"Input IDs shape:\", input_ids.shape)\n",
    "        # print(\"Attention mask shape:\", attention_masks.shape)\n",
    "        # Passer input_ids et attention_masks au modèle\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_masks)\n",
    "        token_embeddings = outputs.last_hidden_state\n",
    "    \n",
    "        entity_embeddings, text_embeddings = self.split_embeddings(token_embeddings, len(entity_types[0]))\n",
    "        \n",
    "\n",
    "        refined_entity_embeddings = self.entity_ffn(entity_embeddings)\n",
    "        \n",
    "        span_scores = self.compute_span_scores(refined_entity_embeddings, text_embeddings, spans)\n",
    "\n",
    "        if binary_labels is not None:\n",
    "            loss = self.compute_loss(span_scores, binary_labels)\n",
    "            return span_scores, loss\n",
    "        \n",
    "        return span_scores\n",
    "\n",
    "    def split_embeddings(self, token_embeddings, num_entity_types):\n",
    "        entity_embeddings = token_embeddings[:, 0:num_entity_types, :]\n",
    "        text_embeddings = token_embeddings[:, num_entity_types + 1:, :]\n",
    "        \n",
    "        return entity_embeddings, text_embeddings\n",
    "\n",
    "    # def compute_span_scores(self, entity_embeddings, text_embeddings, spans):\n",
    "    #     batch_size, text_length, hidden_size = text_embeddings.shape\n",
    "    #     num_entity_types = entity_embeddings.size(1)\n",
    "        \n",
    "    #     # Limiter la longueur des spans\n",
    "    #     self.span_max_length = min(self.span_max_length, text_length - 1)\n",
    "    #     max_spans_per_batch = max(len(s) for s in spans)\n",
    "\n",
    "    #     # Initialisation de la matrice des scores\n",
    "    #     span_scores = torch.zeros((batch_size, max_spans_per_batch, num_entity_types), device=text_embeddings.device)\n",
    "        \n",
    "    #     # Parcourir chaque élément du batch\n",
    "    #     for b in range(batch_size):\n",
    "    #         span_list = spans[b]\n",
    "    #         valid_spans = [\n",
    "    #             (i, j) for i, j in span_list \n",
    "    #             if i < text_length and j < text_length\n",
    "    #         ]\n",
    "\n",
    "    #         if not valid_spans:\n",
    "    #             continue  # Si aucun span valide, on passe\n",
    "\n",
    "    #         # Construction des vecteurs des spans (concaténation des extrémités)\n",
    "    #         span_indices = torch.tensor(valid_spans, device=text_embeddings.device)\n",
    "    #         i_indices, j_indices = span_indices[:, 0], span_indices[:, 1]\n",
    "    #         span_reprs = torch.cat(\n",
    "    #             [text_embeddings[b, i_indices, :], text_embeddings[b, j_indices, :]], dim=-1\n",
    "    #         )\n",
    "            \n",
    "    #         # Transformer les représentations des spans\n",
    "    #         span_reprs = self.span_ffn(span_reprs)  # [nb_spans, hidden_size]\n",
    "            \n",
    "    #         # Calcul direct du produit scalaire\n",
    "    #         scores = torch.einsum(\"sh,eh->se\", span_reprs, entity_embeddings[b])  # [nb_spans, num_entity_types]\n",
    "            \n",
    "    #         # Appliquer la sigmoïde\n",
    "    #         scores = self.sigmoid(scores)\n",
    "            \n",
    "    #         # Remplir les scores dans la matrice batch\n",
    "    #         span_scores[b, :len(valid_spans), :] = scores\n",
    "\n",
    "    #     return span_scores\n",
    "    \n",
    "    def compute_span_scores(self, entity_embeddings, text_embeddings, spans):\n",
    "        \"\"\"\n",
    "        Calcule les scores des spans en une seule passe vectorisée.\n",
    "        \"\"\"\n",
    "        batch_size, text_length, hidden_size = text_embeddings.shape\n",
    "        \n",
    "        # Limiter la longueur des spans\n",
    "        self.span_max_length = min(self.span_max_length, text_length - 1)\n",
    "\n",
    "        # Initialisation des indices valides pour les spans\n",
    "        batch_span_indices = []\n",
    "        batch_span_lengths = []\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            valid_spans = [\n",
    "                (i, j) for i, j in spans[b]\n",
    "                if i < text_length and j < text_length\n",
    "            ]\n",
    "            batch_span_indices.append(valid_spans)\n",
    "            batch_span_lengths.append(len(valid_spans))\n",
    "\n",
    "        max_valid_spans = max(batch_span_lengths)\n",
    "\n",
    "        # Construire un tenseur pour les indices valides (batch, max_valid_spans, 2)\n",
    "        padded_indices = torch.zeros((batch_size, max_valid_spans, 2), dtype=torch.long, device=text_embeddings.device)\n",
    "        for b in range(batch_size):\n",
    "            if batch_span_lengths[b] > 0:\n",
    "                span_indices = torch.tensor(batch_span_indices[b], device=text_embeddings.device)\n",
    "                padded_indices[b, :batch_span_lengths[b]] = span_indices\n",
    "\n",
    "        # Récupération des embeddings des spans\n",
    "        i_indices = padded_indices[:, :, 0].unsqueeze(-1).expand(-1, -1, hidden_size)  # (batch, max_valid_spans, hidden_size)\n",
    "        j_indices = padded_indices[:, :, 1].unsqueeze(-1).expand(-1, -1, hidden_size)\n",
    "\n",
    "        start_embeddings = torch.gather(text_embeddings, 1, i_indices)  # (batch, max_valid_spans, hidden_size)\n",
    "        end_embeddings = torch.gather(text_embeddings, 1, j_indices)    # (batch, max_valid_spans, hidden_size)\n",
    "\n",
    "        # Concaténer les embeddings des extrémités et passer dans la FFN\n",
    "        span_reprs = torch.cat([start_embeddings, end_embeddings], dim=-1)  # (batch, max_valid_spans, 2 * hidden_size)\n",
    "        span_reprs = self.span_ffn(span_reprs)                              # (batch, max_valid_spans, hidden_size)\n",
    "\n",
    "        # Calcul des scores pour toutes les entités\n",
    "        scores = torch.einsum(\"bsh,beh->bse\", span_reprs, entity_embeddings)  # (batch, max_valid_spans, num_entity_types)\n",
    "\n",
    "        # Appliquer la sigmoïde pour les scores finaux\n",
    "        span_scores = self.sigmoid(scores)\n",
    "\n",
    "        return span_scores\n",
    "\n",
    "\n",
    "    def compute_loss(self, span_scores, binary_labels):\n",
    "        \"\"\"\n",
    "        Calcul de la perte binaire cross-entropy entre les scores et les étiquettes.\n",
    "        \"\"\"\n",
    "        # print(f\"span_scores shape: {span_scores.shape}\")\n",
    "        # print(f\"binary_labels shape: {binary_labels.shape}\")\n",
    "\n",
    "        # Appliquer la perte\n",
    "        loss = self.loss_fn(span_scores, binary_labels)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 7/2294 [03:01<18:32:05, 29.18s/batch, Batch Loss=0.0301]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Hyperparamètres\n",
    "num_epochs = 1\n",
    "learning_rate = 1e-5\n",
    "\n",
    "# Optimiseur et scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = get_scheduler(\n",
    "    \"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * num_epochs\n",
    ")\n",
    "\n",
    "# Fonction d'entraînement avec tqdm\n",
    "def train_epoch(model, train_loader, optimizer, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    # Ajout de tqdm pour afficher la progression\n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\", unit=\"batch\")\n",
    "    for batch in progress_bar:\n",
    "        input_ids, attention_masks, spans, entity_ids, binary_labels = [b.to(device) for b in batch]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        span_scores, loss = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_masks=attention_masks,\n",
    "            entity_types=entity_ids,\n",
    "            spans=spans,\n",
    "            binary_labels=binary_labels\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Mise à jour de la barre de progression\n",
    "        progress_bar.set_postfix({\"Batch Loss\": loss.item()})\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    return avg_loss\n",
    "\n",
    "# Boucle d'entraînement avec tqdm\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler)\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Loss: 8.5154:   3%|▎         | 80/2295 [04:10<1:55:49,  3.14s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Utiliser tqdm pour afficher la barre de progression avec la train loss\u001b[39;00m\n\u001b[0;32m     43\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Loss: 0.0000\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 45\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\doria\\anaconda3\\envs\\vincentorch\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\doria\\anaconda3\\envs\\vincentorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\doria\\anaconda3\\envs\\vincentorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\doria\\anaconda3\\envs\\vincentorch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\doria\\anaconda3\\envs\\vincentorch\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:419\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[1;32mIn[7], line 36\u001b[0m, in \u001b[0;36mNERDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     34\u001b[0m     span_labels \u001b[38;5;241m=\u001b[39m token_labels[start:end \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m entity_idx, entity_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(entity_ids):\n\u001b[1;32m---> 36\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mentity_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mspan_labels\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     37\u001b[0m             binary_labels[span_idx, entity_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m input_id, attention_mask, spans, entity_ids, binary_labels\n",
      "File \u001b[1;32mc:\\Users\\doria\\anaconda3\\envs\\vincentorch\\Lib\\site-packages\\torch\\_tensor.py:1057\u001b[0m, in \u001b[0;36mTensor.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state():\n\u001b[0;32m   1049\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1050\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterating over a tensor might cause the trace to be incorrect. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1051\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing a tensor of different shape won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt change the number of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1055\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1056\u001b[0m     )\n\u001b[1;32m-> 1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.optim as optim\n",
    "# from transformers import get_scheduler\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # # Hyperparamètres\n",
    "# learning_rate_pretrained = 1e-5\n",
    "# learning_rate_non_pretrained = 5e-5\n",
    "# dropout_rate = 0.4\n",
    "# num_entity_types = len(entity_to_id) \n",
    "# num_epochs = 3\n",
    "# max_steps = 30000\n",
    "# warmup_steps = int(0.1 * max_steps)  # 10% warmup\n",
    "\n",
    "# # Initialiser le modèle\n",
    "# model = GLiNER(pretrained_model_name=\"microsoft/deberta-v3-base\", num_entity_types=num_entity_types, dropout_rate=dropout_rate)\n",
    "# model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Configurer deux groupes de paramètres avec des taux d'apprentissage distincts\n",
    "# optimizer = optim.AdamW([\n",
    "#     {\"params\": model.encoder.parameters(), \"lr\": learning_rate_pretrained},\n",
    "#     {\"params\": model.entity_embeddings.parameters(), \"lr\": learning_rate_non_pretrained},\n",
    "#     {\"params\": model.span_ffn.parameters(), \"lr\": learning_rate_non_pretrained},\n",
    "#     {\"params\": model.score_ffn.parameters(), \"lr\": learning_rate_non_pretrained}\n",
    "# ])\n",
    "\n",
    "# # Scheduler\n",
    "# scheduler = get_scheduler(\n",
    "#     \"cosine\",\n",
    "#     optimizer=optimizer,\n",
    "#     num_warmup_steps=warmup_steps,\n",
    "#     num_training_steps=max_steps\n",
    "# )\n",
    "\n",
    "# # Boucle d'entraînement\n",
    "# step = 0\n",
    "# for epoch in range(num_epochs):\n",
    "#     print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "#     model.train()\n",
    "#     train_loss = 0\n",
    "\n",
    "#     # Utiliser tqdm pour afficher la barre de progression avec la train loss\n",
    "#     progress_bar = tqdm(train_loader, desc=\"Train Loss: 0.0000\")\n",
    "\n",
    "#     for batch in progress_bar:\n",
    "#         input_ids, attention_masks, spans, entity_ids, binary_labels = batch\n",
    "#         input_ids = input_ids.to(\"cuda\")\n",
    "#         attention_masks = attention_masks.to(\"cuda\")\n",
    "#         entity_ids = entity_ids.to(\"cuda\")\n",
    "#         binary_labels = binary_labels.to(\"cuda\")\n",
    "\n",
    "#         # Forward pass\n",
    "#         optimizer.zero_grad()\n",
    "#         scores, loss = model(input_ids, attention_masks, spans, entity_ids, binary_labels)\n",
    "\n",
    "#         # Backward pass\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         scheduler.step()\n",
    "\n",
    "#         train_loss += loss.item()\n",
    "#         step += 1\n",
    "\n",
    "#         # Mettre à jour la description de tqdm\n",
    "#         avg_loss = train_loss / (progress_bar.n + 1)  # Moyenne des pertes jusqu'à présent\n",
    "#         progress_bar.set_description(f\"Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "#         # Arrêter après 30k étapes\n",
    "#         if step >= max_steps:\n",
    "#             break\n",
    "\n",
    "#     train_loss /= len(train_loader)\n",
    "#     print(f\"Train Loss: {train_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_accuracy(scores, binary_labels, threshold=0.5):\n",
    "#     # Transformer les scores en binary_scores (0 ou 1 selon le seuil)\n",
    "#     binary_scores = (scores >= threshold).float()  # scores >= threshold devient 1, sinon 0\n",
    "\n",
    "#     # Trouver l'élément le plus élevé dans chaque span\n",
    "#     # Chaque span aura sa valeur la plus élevée transformée en 1\n",
    "#     max_scores = scores.max(dim=-1, keepdim=True).values  # Maximum score pour chaque span\n",
    "#     binary_scores = (scores == max_scores).float()  # Les indices du max deviennent 1, le reste 0\n",
    "\n",
    "#     # Calculer l'accuracy\n",
    "#     correct = (binary_scores == binary_labels).float()  # Comparer les prédictions avec les labels\n",
    "#     accuracy = correct.sum() / correct.numel()  # Moyenne de la précision\n",
    "#     print(binary_scores)\n",
    "#     print(binary_labels)\n",
    "#     return accuracy.item()\n",
    "\n",
    "# def calculate_accuracy(scores, binary_labels, threshold=0.5):\n",
    "#     # Transformer les scores en binary_scores (0 ou 1 selon le seuil)\n",
    "#     binary_scores = (scores >= threshold).float()  # scores >= threshold devient 1, sinon 0\n",
    "\n",
    "#     # Trouver l'élément le plus élevé dans chaque span\n",
    "#     max_scores = scores.max(dim=-1, keepdim=True).values  # Maximum score pour chaque span\n",
    "#     binary_scores = (scores == max_scores).float()  # Les indices du max deviennent 1, le reste 0\n",
    "\n",
    "#     # Masquer les 0 dans les labels, ne considérer que les entités (les labels == 1)\n",
    "#     mask = binary_labels == 1\n",
    "\n",
    "#     # Comparer uniquement les entités (où binary_labels est égal à 1)\n",
    "#     correct = (binary_scores == binary_labels) * mask.float()  # Ne comparer que pour les 1\n",
    "\n",
    "#     # Calculer l'accuracy sur les entités seulement\n",
    "#     accuracy = correct.sum() / mask.sum()  # Diviser par le nombre d'entités\n",
    "\n",
    "#     return accuracy.item()\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Fonction pour calculer la précision, le rappel, le F1-score et la matrice de confusion\n",
    "def calculate_metrics(binary_scores, binary_labels):\n",
    "    # Déplacer les tensors vers le CPU avant de les convertir en NumPy\n",
    "    binary_scores_flat = binary_scores.cpu().flatten()\n",
    "    binary_labels_flat = binary_labels.cpu().flatten()\n",
    "\n",
    "    # Calcul des métriques\n",
    "    precision = precision_score(binary_labels_flat, binary_scores_flat)\n",
    "    recall = recall_score(binary_labels_flat, binary_scores_flat)\n",
    "    f1 = f1_score(binary_labels_flat, binary_scores_flat)\n",
    "\n",
    "    # Matrice de confusion\n",
    "    cm = confusion_matrix(binary_labels_flat, binary_scores_flat)\n",
    "\n",
    "    return precision, recall, f1, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(confusion_matrix, normalize=False):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    # Normalisation de la matrice de confusion si nécessaire\n",
    "    if normalize:\n",
    "        confusion_matrix = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    print(confusion_matrix)\n",
    "    # Affichage de la matrice de confusion avec format ajusté\n",
    "    sns.heatmap(confusion_matrix, annot=True, fmt='.4f' if normalize else 'g', cmap='Blues', cbar=False, \n",
    "                xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "                yticklabels=['True Negative', 'True Positive'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test phase\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "total_precision = 0\n",
    "total_recall = 0\n",
    "total_f1 = 0\n",
    "confusion_matrix_total = torch.zeros(2, 2)  # Confusion matrix for binary classification\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids, attention_masks, spans, entity_ids, binary_labels = batch\n",
    "        input_ids = input_ids.to(\"cuda\")\n",
    "        attention_masks = attention_masks.to(\"cuda\")\n",
    "        entity_ids = entity_ids.to(\"cuda\")\n",
    "        binary_labels = binary_labels.to(\"cuda\")\n",
    "\n",
    "        # Forward pass\n",
    "        scores, loss = model(input_ids, attention_masks, spans, entity_ids, binary_labels)\n",
    "        \n",
    "        # Calcul des métriques\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Calcul des autres métriques\n",
    "        binary_scores = (scores >= 0.5).float()  # Convertir les scores en prédictions binaires\n",
    "        precision, recall, f1, cm = calculate_metrics(binary_scores, binary_labels)\n",
    "        \n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "        total_f1 += f1\n",
    "        confusion_matrix_total += torch.tensor(cm)\n",
    "\n",
    "# Moyenne des métriques\n",
    "test_loss /= len(test_loader)\n",
    "average_precision = total_precision / len(test_loader)\n",
    "average_recall = total_recall / len(test_loader)\n",
    "average_f1 = total_f1 / len(test_loader)\n",
    "confusion_matrix_total = confusion_matrix_total.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cm[0, 0] = TN\n",
    "- cm[0, 1] = FP\n",
    "- cm[1, 0] = FN\n",
    "- cm[1, 1] = TP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1609\n",
      "Average Precision: 0.0231\n",
      "Average Recall: 0.0631\n",
      "Average F1-score: 0.0324\n",
      "Confusion Matrix:\n",
      "[[0.95969806 0.04030194]\n",
      " [0.93659348 0.06340652]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Affichage des résultats\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Average Precision: {average_precision:.4f}\")\n",
    "print(f\"Average Recall: {average_recall:.4f}\")\n",
    "print(f\"Average F1-score: {average_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "# Affichage de la matrice de confusion après le calcul des métriques\n",
    "plot_confusion_matrix(confusion_matrix_total,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save & Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le modèle complet\n",
    "torch.save(model, \"model_full2.pth\")\n",
    "# Sauvegarder le modèle\n",
    "torch.save(model.state_dict(), \"model2.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\doria\\anaconda3\\envs\\vincentorch\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\Users\\doria\\anaconda3\\envs\\vincentorch\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Charger le tokenizer et le modèle pré-entraîné\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n",
    "model2 = GLiNER(pretrained_model_name=\"microsoft/deberta-v3-base\", num_entity_types=len(entity_to_id))\n",
    "model2.load_state_dict(torch.load(\"model.pth\"))  # Charger le modèle pré-entraîné\n",
    "model2 = model2.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phrase d'exemple\n",
    "sentence = \"Paul is walking to University\"\n",
    "entity_types_to_detect = [\"person\", \"organization\"]\n",
    "\n",
    "# Tokeniser la phrase\n",
    "# Tokenize the entire text\n",
    "encoded = tokenizer(sentence, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "input_id = encoded[\"input_ids\"][0]\n",
    "attention_mask = (encoded[\"attention_mask\"][0])\n",
    "\n",
    "current_entity_set = set()\n",
    "for entity_type in entity_types_to_detect:\n",
    "    if entity_type in entity_to_id:\n",
    "        current_entity_set.add(entity_to_id[entity_type])\n",
    "entity_tensor = torch.tensor(sorted(current_entity_set), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Calcul des scores pour chaque token\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     scores, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# # Récupérer les entités prédites\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# predicted_entities = []\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# for token_idx, score in enumerate(scores[0]):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# for token, entity_type in predicted_entities:\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#     print(f\"Token: {token}, Entity Type: {entity_type}\")\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\doria\\anaconda3\\envs\\vincentorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\doria\\anaconda3\\envs\\vincentorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[40], line 33\u001b[0m, in \u001b[0;36mGLiNER.forward\u001b[1;34m(self, input_ids, attention_masks, spans, entity_ids, binary_labels, threshold)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_masks, spans, entity_ids, binary_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m):\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# Encoder les tokens avec le transformer\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_masks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     token_embeddings \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state  \u001b[38;5;66;03m# [batch_size, seq_length, hidden_size]\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# Obtenir les embeddings des entités\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\doria\\anaconda3\\envs\\vincentorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\doria\\anaconda3\\envs\\vincentorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\doria\\anaconda3\\envs\\vincentorch\\Lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:1055\u001b[0m, in \u001b[0;36mDebertaV2Model.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token_type_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1053\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m-> 1055\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1061\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1063\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m   1064\u001b[0m     embedding_output,\n\u001b[0;32m   1065\u001b[0m     attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1068\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1069\u001b[0m )\n\u001b[0;32m   1070\u001b[0m encoded_layers \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\doria\\anaconda3\\envs\\vincentorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\doria\\anaconda3\\envs\\vincentorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\doria\\anaconda3\\envs\\vincentorch\\Lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:890\u001b[0m, in \u001b[0;36mDebertaV2Embeddings.forward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, mask, inputs_embeds)\u001b[0m\n\u001b[0;32m    888\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m    889\u001b[0m         mask \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 890\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m mask \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39mto(embeddings\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    893\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m embeddings \u001b[38;5;241m*\u001b[39m mask\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "# Effectuer la prédiction\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Calcul des scores pour chaque token\n",
    "    scores, _ = model(input_ids, attention_mask, spans=None, entity_ids=None)\n",
    "\n",
    "# # Récupérer les entités prédites\n",
    "# predicted_entities = []\n",
    "# for token_idx, score in enumerate(scores[0]):\n",
    "#     token = tokens[token_idx]\n",
    "#     max_score_idx = score.argmax().item()  # Trouver l'indice de l'entité avec le score le plus élevé\n",
    "#     entity_type = list(entity_to_id.keys())[max_score_idx - 1]  # Convertir l'indice en nom d'entité (ignorer l'entité \"non-entité\" qui est mappée à 0)\n",
    "    \n",
    "#     # Vérifier si l'entité est dans les types recherchés\n",
    "#     if entity_type in entity_types_to_detect:\n",
    "#         predicted_entities.append((token, entity_type))\n",
    "\n",
    "# # Afficher les résultats\n",
    "# print(\"Entities detected:\")\n",
    "# for token, entity_type in predicted_entities:\n",
    "#     print(f\"Token: {token}, Entity Type: {entity_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vincentorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
